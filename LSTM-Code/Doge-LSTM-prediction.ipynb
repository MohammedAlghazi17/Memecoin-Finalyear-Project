{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>6259550</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>4246520</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>2231080</td>\n",
       "      <td>0.001201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>3288960</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>2481270</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-24</th>\n",
       "      <td>0.134690</td>\n",
       "      <td>0.131502</td>\n",
       "      <td>0.134202</td>\n",
       "      <td>0.131947</td>\n",
       "      <td>436620221</td>\n",
       "      <td>0.131947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-25</th>\n",
       "      <td>0.167735</td>\n",
       "      <td>0.123869</td>\n",
       "      <td>0.131936</td>\n",
       "      <td>0.157959</td>\n",
       "      <td>5177823685</td>\n",
       "      <td>0.157959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-26</th>\n",
       "      <td>0.165278</td>\n",
       "      <td>0.137424</td>\n",
       "      <td>0.157777</td>\n",
       "      <td>0.137767</td>\n",
       "      <td>4529010503</td>\n",
       "      <td>0.137767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-27</th>\n",
       "      <td>0.145405</td>\n",
       "      <td>0.136272</td>\n",
       "      <td>0.137847</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>1765370972</td>\n",
       "      <td>0.139700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-28</th>\n",
       "      <td>0.142264</td>\n",
       "      <td>0.137148</td>\n",
       "      <td>0.139953</td>\n",
       "      <td>0.137148</td>\n",
       "      <td>1287613312</td>\n",
       "      <td>0.137148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1632 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low      Open     Close      Volume  Adj Close\n",
       "Date                                                                     \n",
       "2017-11-09  0.001415  0.001181  0.001207  0.001415     6259550   0.001415\n",
       "2017-11-10  0.001431  0.001125  0.001421  0.001163     4246520   0.001163\n",
       "2017-11-11  0.001257  0.001141  0.001146  0.001201     2231080   0.001201\n",
       "2017-11-12  0.001210  0.001002  0.001189  0.001038     3288960   0.001038\n",
       "2017-11-13  0.001212  0.001019  0.001046  0.001211     2481270   0.001211\n",
       "...              ...       ...       ...       ...         ...        ...\n",
       "2022-04-24  0.134690  0.131502  0.134202  0.131947   436620221   0.131947\n",
       "2022-04-25  0.167735  0.123869  0.131936  0.157959  5177823685   0.157959\n",
       "2022-04-26  0.165278  0.137424  0.157777  0.137767  4529010503   0.137767\n",
       "2022-04-27  0.145405  0.136272  0.137847  0.139700  1765370972   0.139700\n",
       "2022-04-28  0.142264  0.137148  0.139953  0.137148  1287613312   0.137148\n",
       "\n",
       "[1632 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doge = web.DataReader('DOGE-USD', 'yahoo')\n",
    "doge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        High       Low      Open     Close      Volume  Adj Close  \\\n",
      "0   0.174406  0.168271  0.174406  0.170088   505900382   0.170088   \n",
      "1   0.138747  0.135565  0.137213  0.137541   383506507   0.137541   \n",
      "2   0.133649  0.127810  0.132998  0.129610   518193386   0.129610   \n",
      "3   0.148558  0.137088  0.138903  0.146453  1047399132   0.146453   \n",
      "4   0.172339  0.168128  0.170151  0.168803   541922892   0.168803   \n",
      "5   0.147592  0.137250  0.137523  0.147503   580740990   0.147503   \n",
      "6   0.129856  0.121544  0.129631  0.122591   650665594   0.122591   \n",
      "7   0.155312  0.142008  0.146413  0.148591  2253509569   0.148591   \n",
      "8   0.157354  0.144031  0.144379  0.148948  1581065491   0.148948   \n",
      "9   0.116231  0.110686  0.115080  0.111608   373430106   0.111608   \n",
      "10  0.142608  0.137067  0.138070  0.140080   890728707   0.140080   \n",
      "11  0.150132  0.143649  0.148869  0.146003   898042727   0.146003   \n",
      "12  0.118967  0.110817  0.111607  0.114048   822092169   0.114048   \n",
      "13  0.146633  0.138101  0.140053  0.143920  1759067761   0.143920   \n",
      "14  0.152199  0.145203  0.145996  0.151761   674961496   0.151761   \n",
      "15  0.114213  0.110937  0.114043  0.112784   400614617   0.112784   \n",
      "16  0.149287  0.142767  0.143917  0.146026  1140382087   0.146026   \n",
      "17  0.151824  0.146771  0.151779  0.149095   505588732   0.149095   \n",
      "18  0.116908  0.112364  0.112779  0.116908   537170937   0.116908   \n",
      "19  0.147811  0.142093  0.146017  0.143712   584019179   0.143712   \n",
      "20  0.149889  0.138071  0.149050  0.138552   721382126   0.138552   \n",
      "21  0.118710  0.116281  0.116907  0.116502   412838814   0.116502   \n",
      "22  0.144709  0.138995  0.143693  0.139459   636442285   0.139459   \n",
      "23  0.142097  0.136960  0.138594  0.138768   563817289   0.138768   \n",
      "24  0.119375  0.114568  0.116490  0.119306   410862503   0.119306   \n",
      "25  0.140461  0.134384  0.139471  0.140286   909718484   0.140286   \n",
      "26  0.145906  0.138751  0.138764  0.141206   655782652   0.141206   \n",
      "27  0.124573  0.118530  0.119278  0.123569   628081786   0.123569   \n",
      "28  0.144141  0.139500  0.140297  0.142665   679511647   0.142665   \n",
      "29  0.141197  0.135852  0.141197  0.136868   490138547   0.136868   \n",
      "30  0.123919  0.117991  0.123579  0.119154   428111799   0.119154   \n",
      "31  0.146241  0.139595  0.142677  0.140878  1068542289   0.140878   \n",
      "32  0.141345  0.128246  0.136838  0.128490   913773124   0.128490   \n",
      "33  0.121332  0.118306  0.119146  0.119339   439486516   0.119339   \n",
      "34  0.142448  0.135255  0.140868  0.136365   740549793   0.136365   \n",
      "35  0.131696  0.125365  0.128488  0.131553   711967119   0.131553   \n",
      "36  0.125350  0.119014  0.119333  0.122481   610507111   0.122481   \n",
      "37  0.137908  0.134985  0.136357  0.136395   505251263   0.136395   \n",
      "38  0.135337  0.127846  0.131561  0.127846   587472906   0.127846   \n",
      "39  0.130713  0.121361  0.122487  0.129727   998922753   0.129727   \n",
      "40  0.136495  0.133810  0.136387  0.134241   349740069   0.134241   \n",
      "41  0.127851  0.109555  0.127821  0.123813  2046477370   0.123813   \n",
      "42  0.140605  0.128455  0.129722  0.136550  2017926806   0.136550   \n",
      "43  0.134690  0.131502  0.134202  0.131947   436620221   0.131947   \n",
      "44  0.128181  0.120983  0.123843  0.127576   805161073   0.127576   \n",
      "45  0.137275  0.128782  0.136603  0.131013   882486375   0.131013   \n",
      "46  0.167735  0.123869  0.131936  0.157959  5177823685   0.157959   \n",
      "47  0.130071  0.126199  0.127568  0.127647   535575654   0.127647   \n",
      "48  0.136495  0.129878  0.131010  0.135868   610401998   0.135868   \n",
      "49  0.165278  0.137424  0.157777  0.137767  4529010503   0.137767   \n",
      "50  0.128235  0.122053  0.127639  0.123111   592809151   0.123111   \n",
      "51  0.144858  0.135703  0.135900  0.144732  1445019558   0.144732   \n",
      "52  0.145405  0.136272  0.137847  0.139700  1765370972   0.139700   \n",
      "53  0.134479  0.121954  0.123118  0.133156   765755924   0.133156   \n",
      "54  0.152737  0.142457  0.144725  0.142657  1476875507   0.142657   \n",
      "55  0.142264  0.137544  0.139953  0.138204  1302681344   0.138204   \n",
      "56  0.148559  0.141290  0.142557  0.144470   961074557   0.144470   \n",
      "57  0.144997  0.139880  0.144456  0.143210   884305263   0.143210   \n",
      "58  0.147220  0.137172  0.143184  0.137826  1055136949   0.137826   \n",
      "\n",
      "    Polarity Score  \n",
      "0         0.095867  \n",
      "1         0.146020  \n",
      "2         0.138143  \n",
      "3         0.146417  \n",
      "4         0.071015  \n",
      "5         0.096342  \n",
      "6         0.085107  \n",
      "7         0.090832  \n",
      "8         0.113200  \n",
      "9         0.111060  \n",
      "10        0.119920  \n",
      "11        0.367391  \n",
      "12        0.075841  \n",
      "13        0.167889  \n",
      "14        0.150535  \n",
      "15        0.100922  \n",
      "16        0.115242  \n",
      "17        0.010105  \n",
      "18        0.076036  \n",
      "19        0.131267  \n",
      "20        0.232539  \n",
      "21        0.133072  \n",
      "22        0.129466  \n",
      "23        0.245144  \n",
      "24        0.089275  \n",
      "25        0.141833  \n",
      "26        0.000168  \n",
      "27        0.223525  \n",
      "28        0.141011  \n",
      "29        0.219473  \n",
      "30        0.110555  \n",
      "31        0.127655  \n",
      "32        0.135519  \n",
      "33        0.115944  \n",
      "34        0.131129  \n",
      "35        0.112503  \n",
      "36        0.000000  \n",
      "37        0.112926  \n",
      "38        0.153502  \n",
      "39        0.140484  \n",
      "40        0.121865  \n",
      "41        0.109284  \n",
      "42        0.117736  \n",
      "43        0.101390  \n",
      "44        0.107181  \n",
      "45        0.161422  \n",
      "46        0.123299  \n",
      "47        0.141459  \n",
      "48        0.227658  \n",
      "49        0.164302  \n",
      "50        0.199485  \n",
      "51        0.169030  \n",
      "52        0.148283  \n",
      "53        0.131502  \n",
      "54        0.153586  \n",
      "55        0.128671  \n",
      "56        0.114973  \n",
      "57        0.107061  \n",
      "58        0.083907  \n"
     ]
    }
   ],
   "source": [
    "#lstm_data = np.genfromtxt('./sample_data/lstm.csv', delimiter=',', skip_header=True)\n",
    "lstm_data = read_csv('lstmdoge.csv')\n",
    "lstm_data = lstm_data.drop(['Date'], axis=1)\n",
    "print(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X = lstm_data.drop(['Close'], axis=1)\n",
    "lstm_data_y = lstm_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 5 # how many days to look back\n",
    "batch_size = 3 # size of batches used when training\n",
    "n_feat = 6 # number of features \n",
    "n_target = 2\n",
    "n_validation = 6\n",
    "n_test = 8\n",
    "n_train = lstm_data_X.shape[0] - n_validation - n_test - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_data_X_train = lstm_data_X.iloc[:30,:]\n",
    "#lstm_data_X_val = lstm_data_X.iloc[30:40,:]\n",
    "#lstm_data_X_test = lstm_data_X.iloc[40:52,:]\n",
    "\n",
    "#lstm_data_y_train = lstm_data_y.iloc[:30]\n",
    "#lstm_data_y_val = lstm_data_y.iloc[30:40]\n",
    "#lstm_data_y_test = lstm_data_y.iloc[40:52]\n",
    "# Convert to numpy arrays\n",
    "#X_train = lstm_data_X_train.to_numpy()\n",
    "#X_val = lstm_data_X_val.to_numpy()\n",
    "#X_test = lstm_data_X_test.to_numpy()\n",
    "#y_train = lstm_data_y_train.to_numpy()\n",
    "#y_val = lstm_data_y_val.to_numpy()\n",
    "#y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X_train = lstm_data_X.iloc[:n_train,:]\n",
    "lstm_data_X_val = lstm_data_X.iloc[n_train:n_train + n_validation,:]\n",
    "lstm_data_X_test = lstm_data_X.iloc[n_train + n_validation:n_train + n_validation + n_test,:]\n",
    "\n",
    "lstm_data_y_train = lstm_data_y.iloc[:n_train]\n",
    "lstm_data_y_val = lstm_data_y.iloc[n_train:n_train + n_validation]\n",
    "lstm_data_y_test = lstm_data_y.iloc[n_train + n_validation:n_train + n_validation + n_test]\n",
    "# Convert to numpy arrays\n",
    "X_train = lstm_data_X_train.to_numpy()\n",
    "X_val = lstm_data_X_val.to_numpy()\n",
    "X_test = lstm_data_X_test.to_numpy()\n",
    "y_train = lstm_data_y_train.to_numpy()\n",
    "y_val = lstm_data_y_val.to_numpy()\n",
    "y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "        1.23111002e-01, 1.99485454e-01],\n",
       "       [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "        1.44731998e-01, 1.69029840e-01],\n",
       "       [1.45404994e-01, 1.36271998e-01, 1.37847006e-01, 1.76537097e+09,\n",
       "        1.39699996e-01, 1.48283467e-01],\n",
       "       [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "        1.33156002e-01, 1.31502325e-01],\n",
       "       [1.52737007e-01, 1.42456993e-01, 1.44724995e-01, 1.47687551e+09,\n",
       "        1.42656997e-01, 1.53586280e-01],\n",
       "       [1.42263845e-01, 1.37544140e-01, 1.39953479e-01, 1.30268134e+09,\n",
       "        1.38204291e-01, 1.28670540e-01],\n",
       "       [1.48559004e-01, 1.41289994e-01, 1.42556995e-01, 9.61074557e+08,\n",
       "        1.44470006e-01, 1.14973180e-01],\n",
       "       [1.44997001e-01, 1.39880002e-01, 1.44455999e-01, 8.84305263e+08,\n",
       "        1.43209994e-01, 1.07060620e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.123111  , 0.144732  , 0.1397    , 0.133156  , 0.142657  ,\n",
       "       0.13820429, 0.14447001, 0.14320999])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = TimeseriesGenerator(X_train, y_train, length=look_back, batch_size=batch_size)\n",
    "val_data_gen = TimeseriesGenerator(X_val, y_val, length=look_back, batch_size=batch_size)\n",
    "test_data_gen = TimeseriesGenerator(X_test, y_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n"
     ]
    }
   ],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(train_data_gen)):\n",
    "    x, y = train_data_gen[i]\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 5, 32)             4992      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 32)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,345\n",
      "Trainable params: 13,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, input_shape=(look_back, n_feat), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(LSTM(32))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_23544/192094070.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model_lstm.fit_generator(train_data_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 5s 157ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 2.6116e-04 - val_mse: 2.6116e-04\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 2.3032e-05 - val_mse: 2.3032e-05\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 2.1666e-04 - val_mse: 2.1666e-04\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 8.8016e-04 - val_mse: 8.8016e-04\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 1.1438e-04 - val_mse: 1.1438e-04\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 4.0496e-04 - val_mse: 4.0496e-04\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 3.3253e-04 - val_mse: 3.3253e-04\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 5.6596e-04 - val_mse: 5.6596e-04\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 9.1964e-04 - val_mse: 9.1964e-04\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 7.4203e-04 - val_mse: 7.4203e-04\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0029 - val_mse: 0.0029\n"
     ]
    }
   ],
   "source": [
    "hist = model_lstm.fit_generator(train_data_gen,\n",
    "                                        steps_per_epoch=10,\n",
    "                                        epochs=20,\n",
    "                                        verbose=1,\n",
    "                                        validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.28234997e-01 1.22052997e-01 1.27638996e-01 5.92809151e+08\n",
      "   1.23111002e-01 1.99485454e-01]\n",
      "  [1.44858003e-01 1.35702997e-01 1.35900006e-01 1.44501956e+09\n",
      "   1.44731998e-01 1.69029840e-01]\n",
      "  [1.45404994e-01 1.36271998e-01 1.37847006e-01 1.76537097e+09\n",
      "   1.39699996e-01 1.48283467e-01]\n",
      "  [1.34479001e-01 1.21954001e-01 1.23117998e-01 7.65755924e+08\n",
      "   1.33156002e-01 1.31502325e-01]\n",
      "  [1.52737007e-01 1.42456993e-01 1.44724995e-01 1.47687551e+09\n",
      "   1.42656997e-01 1.53586280e-01]]\n",
      "\n",
      " [[1.44858003e-01 1.35702997e-01 1.35900006e-01 1.44501956e+09\n",
      "   1.44731998e-01 1.69029840e-01]\n",
      "  [1.45404994e-01 1.36271998e-01 1.37847006e-01 1.76537097e+09\n",
      "   1.39699996e-01 1.48283467e-01]\n",
      "  [1.34479001e-01 1.21954001e-01 1.23117998e-01 7.65755924e+08\n",
      "   1.33156002e-01 1.31502325e-01]\n",
      "  [1.52737007e-01 1.42456993e-01 1.44724995e-01 1.47687551e+09\n",
      "   1.42656997e-01 1.53586280e-01]\n",
      "  [1.42263845e-01 1.37544140e-01 1.39953479e-01 1.30268134e+09\n",
      "   1.38204291e-01 1.28670540e-01]]\n",
      "\n",
      " [[1.45404994e-01 1.36271998e-01 1.37847006e-01 1.76537097e+09\n",
      "   1.39699996e-01 1.48283467e-01]\n",
      "  [1.34479001e-01 1.21954001e-01 1.23117998e-01 7.65755924e+08\n",
      "   1.33156002e-01 1.31502325e-01]\n",
      "  [1.52737007e-01 1.42456993e-01 1.44724995e-01 1.47687551e+09\n",
      "   1.42656997e-01 1.53586280e-01]\n",
      "  [1.42263845e-01 1.37544140e-01 1.39953479e-01 1.30268134e+09\n",
      "   1.38204291e-01 1.28670540e-01]\n",
      "  [1.48559004e-01 1.41289994e-01 1.42556995e-01 9.61074557e+08\n",
      "   1.44470006e-01 1.14973180e-01]]] [0.13820429 0.14447001 0.14320999]\n"
     ]
    }
   ],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(test_data_gen)):\n",
    "    x, y = test_data_gen[i]\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_gen[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23544/1362096259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 self.start_index, self.end_index + 1, size=self.batch_size)\n\u001b[0;32m    367\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             rows = np.arange(i, min(i + self.batch_size *\n\u001b[0;32m    370\u001b[0m                                     self.stride, self.end_index + 1), self.stride)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'slice'"
     ]
    }
   ],
   "source": [
    "pred = model_lstm.predict(test_data_gen[len(test_data_gen)-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1.36494994e-01, 1.29877999e-01, 1.31009996e-01, 6.10401998e+08,\n",
       "          1.35867998e-01, 2.27658000e-01],\n",
       "         [1.65278003e-01, 1.37424007e-01, 1.57776996e-01, 4.52901050e+09,\n",
       "          1.37767002e-01, 1.64302360e-01],\n",
       "         [1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "          1.23111002e-01, 1.99485454e-01],\n",
       "         [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "          1.44731998e-01, 1.69029840e-01],\n",
       "         [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "          1.33156002e-01, 1.31502325e-01]],\n",
       " \n",
       "        [[1.65278003e-01, 1.37424007e-01, 1.57776996e-01, 4.52901050e+09,\n",
       "          1.37767002e-01, 1.64302360e-01],\n",
       "         [1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "          1.23111002e-01, 1.99485454e-01],\n",
       "         [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "          1.44731998e-01, 1.69029840e-01],\n",
       "         [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "          1.33156002e-01, 1.31502325e-01],\n",
       "         [1.52737007e-01, 1.42456993e-01, 1.44724995e-01, 1.47687551e+09,\n",
       "          1.42656997e-01, 1.53586280e-01]],\n",
       " \n",
       "        [[1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "          1.23111002e-01, 1.99485454e-01],\n",
       "         [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "          1.44731998e-01, 1.69029840e-01],\n",
       "         [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "          1.33156002e-01, 1.31502325e-01],\n",
       "         [1.52737007e-01, 1.42456993e-01, 1.44724995e-01, 1.47687551e+09,\n",
       "          1.42656997e-01, 1.53586280e-01],\n",
       "         [1.48559004e-01, 1.41289994e-01, 1.42556995e-01, 9.61074557e+08,\n",
       "          1.44470006e-01, 1.14973180e-01]]]),\n",
       " array([0.142657  , 0.14447001, 0.14320999]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15474796],\n",
       "       [0.15474796],\n",
       "       [0.15474796]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test[0:y_test.shape[0]-5], color = 'red', label = 'Real Dogecoin Price')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted Dogecoin Price')\n",
    "plt.title('Doge Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Doge Price')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d2dc41cbfaf67ac4a91a427b68830b69dde48fe3ce74dedd3ecbeef6226b1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
