{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Open      High       Low     Close  Adj Close      Volume  \\\n",
      "0   0.137213  0.138747  0.135565  0.137541   0.137541   383506507   \n",
      "1   0.137523  0.147592  0.137250  0.147503   0.147503   580740990   \n",
      "2   0.144379  0.157354  0.144031  0.148948   0.148948  1581065491   \n",
      "3   0.148869  0.150132  0.143649  0.146003   0.146003   898042727   \n",
      "4   0.145996  0.152199  0.145203  0.151761   0.151761   674961496   \n",
      "5   0.151779  0.151824  0.146771  0.149095   0.149095   505588732   \n",
      "6   0.149050  0.149889  0.138071  0.138552   0.138552   721382126   \n",
      "7   0.138594  0.142097  0.136960  0.138768   0.138768   563817289   \n",
      "8   0.138764  0.145906  0.138751  0.141206   0.141206   655782652   \n",
      "9   0.141197  0.141197  0.135852  0.136868   0.136868   490138547   \n",
      "10  0.136838  0.141345  0.128246  0.128490   0.128490   913773124   \n",
      "11  0.128488  0.131696  0.125365  0.131553   0.131553   711967119   \n",
      "12  0.131561  0.135337  0.127846  0.127846   0.127846   587472906   \n",
      "13  0.127821  0.127851  0.109555  0.123813   0.123813  2046477370   \n",
      "14  0.123843  0.128181  0.120983  0.127576   0.127576   805161073   \n",
      "15  0.127568  0.130071  0.126199  0.127647   0.127647   535575654   \n",
      "16  0.127639  0.128235  0.122053  0.123111   0.123111   592809151   \n",
      "17  0.123118  0.134479  0.121954  0.133156   0.133156   765755924   \n",
      "18  0.132998  0.133649  0.127810  0.129610   0.129610   518193386   \n",
      "19  0.129631  0.129856  0.121544  0.122591   0.122591   650665594   \n",
      "20  0.115080  0.116231  0.110686  0.111608   0.111608   373430106   \n",
      "21  0.111607  0.118967  0.110817  0.114048   0.114048   822092169   \n",
      "22  0.114043  0.114213  0.110937  0.112784   0.112784   400614617   \n",
      "23  0.112779  0.116908  0.112364  0.116908   0.116908   537170937   \n",
      "24  0.116907  0.118710  0.116281  0.116502   0.116502   412838814   \n",
      "25  0.116490  0.119375  0.114568  0.119306   0.119306   410862503   \n",
      "26  0.119278  0.124573  0.118530  0.123569   0.123569   628081786   \n",
      "27  0.123579  0.123919  0.117991  0.119154   0.119154   428111799   \n",
      "28  0.119146  0.121332  0.118306  0.119339   0.119339   439486516   \n",
      "29  0.119333  0.125350  0.119014  0.122481   0.122481   610507111   \n",
      "30  0.122487  0.130713  0.121361  0.129727   0.129727   998922753   \n",
      "31  0.129722  0.140605  0.128455  0.136550   0.136550  2017926806   \n",
      "32  0.136603  0.137275  0.128782  0.131013   0.131013   882486375   \n",
      "33  0.131010  0.136495  0.129878  0.135868   0.135868   610401998   \n",
      "34  0.135900  0.144858  0.135703  0.144732   0.144732  1445019558   \n",
      "35  0.144725  0.152737  0.142457  0.142657   0.142657  1476875507   \n",
      "36  0.142557  0.148559  0.141290  0.144470   0.144470   961074557   \n",
      "37  0.144456  0.144997  0.139880  0.143210   0.143210   884305263   \n",
      "38  0.143184  0.147220  0.137172  0.137826   0.137826  1055136949   \n",
      "39  0.138903  0.148558  0.137088  0.146453   0.146453  1047399132   \n",
      "40  0.146413  0.155312  0.142008  0.148591   0.148591  2253509569   \n",
      "41  0.138070  0.142608  0.137067  0.140080   0.140080   890728707   \n",
      "42  0.140053  0.146633  0.138101  0.143920   0.143920  1759067761   \n",
      "43  0.143917  0.149287  0.142767  0.146026   0.146026  1140382087   \n",
      "44  0.146017  0.147811  0.142093  0.143712   0.143712   584019179   \n",
      "45  0.143693  0.144709  0.138995  0.139459   0.139459   636442285   \n",
      "46  0.139471  0.140461  0.134384  0.140286   0.140286   909718484   \n",
      "\n",
      "        MarktCap   returns  Polarity Score  \n",
      "0   5.262208e+07  0.002230        0.146020  \n",
      "1   7.986524e+07  0.072429        0.096342  \n",
      "2   2.282727e+08  0.031460        0.113200  \n",
      "3   1.336907e+08 -0.019772        0.367391  \n",
      "4   9.854168e+07  0.039438        0.150535  \n",
      "5   7.673775e+07 -0.017567        0.010105  \n",
      "6   1.075220e+08 -0.070713        0.232539  \n",
      "7   7.814169e+07  0.001559        0.245144  \n",
      "8   9.099902e+07  0.017569        0.000168  \n",
      "9   6.920609e+07 -0.030721        0.219473  \n",
      "10  1.250389e+08 -0.061212        0.135519  \n",
      "11  9.147923e+07  0.023838        0.112503  \n",
      "12  7.728852e+07 -0.028179        0.153502  \n",
      "13  2.615828e+08 -0.031546        0.109284  \n",
      "14  9.971356e+07  0.030393        0.107181  \n",
      "15  6.832232e+07  0.000557        0.141459  \n",
      "16  7.566556e+07 -0.035535        0.199485  \n",
      "17  9.427834e+07  0.081593        0.131502  \n",
      "18  6.891869e+07 -0.025415        0.138143  \n",
      "19  8.434643e+07 -0.054155        0.085107  \n",
      "20  4.297434e+07 -0.030642        0.111060  \n",
      "21  9.175124e+07  0.021862        0.075841  \n",
      "22  4.568729e+07 -0.011083        0.100922  \n",
      "23  6.058160e+07  0.036565        0.076036  \n",
      "24  4.826375e+07 -0.003473        0.133072  \n",
      "25  4.786137e+07  0.024068        0.089275  \n",
      "26  7.491634e+07  0.035732        0.223525  \n",
      "27  5.290563e+07 -0.035729        0.110555  \n",
      "28  5.236306e+07  0.001553        0.115944  \n",
      "29  7.285364e+07  0.026328        0.000000  \n",
      "30  1.223551e+08  0.059160        0.140484  \n",
      "31  2.617695e+08  0.052595        0.117736  \n",
      "32  1.205503e+08 -0.040549        0.161422  \n",
      "33  7.996876e+07  0.037057        0.227658  \n",
      "34  1.963782e+08  0.065240        0.169030  \n",
      "35  2.137408e+08 -0.014337        0.153586  \n",
      "36  1.370079e+08  0.012709        0.114973  \n",
      "37  1.277432e+08 -0.008722        0.107061  \n",
      "38  1.510787e+08 -0.037595        0.083907  \n",
      "39  1.454869e+08  0.054278        0.146417  \n",
      "40  3.299431e+08  0.014599        0.090832  \n",
      "41  1.229829e+08  0.014514        0.119920  \n",
      "42  2.463627e+08  0.027413        0.167889  \n",
      "43  1.641204e+08  0.014633        0.115242  \n",
      "44  8.527673e+07 -0.015847        0.131267  \n",
      "45  9.145230e+07 -0.029594        0.129466  \n",
      "46  1.268793e+08  0.005930        0.141833  \n"
     ]
    }
   ],
   "source": [
    "#lstm_data = np.genfromtxt('./sample_data/lstm.csv', delimiter=',', skip_header=True)\n",
    "lstm_data = read_csv('lstm.csv')\n",
    "lstm_data = lstm_data.drop(['Date'], axis=1)\n",
    "print(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X = lstm_data.drop(['Close'], axis=1)\n",
    "lstm_data_y = lstm_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 7 # how many days to look back\n",
    "batch_size = 5 # size of batches used when training\n",
    "n_feat = 8 # number of features \n",
    "n_target = 1\n",
    "n_train = 60\n",
    "n_validation = 5\n",
    "n_test = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X_train = lstm_data_X.iloc[:30,:]\n",
    "lstm_data_X_val = lstm_data_X.iloc[30:72,:]\n",
    "lstm_data_X_test = lstm_data_X.iloc[30:72,:]\n",
    "\n",
    "lstm_data_y_train = lstm_data_y.iloc[:30]\n",
    "lstm_data_y_val = lstm_data_y.iloc[30:55]\n",
    "lstm_data_y_test = lstm_data_y.iloc[55:72]\n",
    "# Convert to numpy arrays\n",
    "X_train = lstm_data_X_train.to_numpy()\n",
    "X_val = lstm_data_X_val.to_numpy()\n",
    "X_test = lstm_data_X_test.to_numpy()\n",
    "y_train = lstm_data_y_train.to_numpy()\n",
    "y_val = lstm_data_y_val.to_numpy()\n",
    "y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22487001e-01,  1.30713001e-01,  1.21361002e-01,\n",
       "         1.29727006e-01,  9.98922753e+08,  1.22355052e+08,\n",
       "         5.91602150e-02,  1.40484460e-01],\n",
       "       [ 1.29721999e-01,  1.40605003e-01,  1.28454998e-01,\n",
       "         1.36549994e-01,  2.01792681e+09,  2.61769499e+08,\n",
       "         5.25949730e-02,  1.17735880e-01],\n",
       "       [ 1.36602998e-01,  1.37274995e-01,  1.28782004e-01,\n",
       "         1.31013006e-01,  8.82486375e+08,  1.20550284e+08,\n",
       "        -4.05491660e-02,  1.61422260e-01],\n",
       "       [ 1.31009996e-01,  1.36494994e-01,  1.29877999e-01,\n",
       "         1.35867998e-01,  6.10401998e+08,  7.99687633e+07,\n",
       "         3.70573290e-02,  2.27658000e-01],\n",
       "       [ 1.35900006e-01,  1.44858003e-01,  1.35702997e-01,\n",
       "         1.44731998e-01,  1.44501956e+09,  1.96378166e+08,\n",
       "         6.52397960e-02,  1.69029840e-01],\n",
       "       [ 1.44724995e-01,  1.52737007e-01,  1.42456993e-01,\n",
       "         1.42656997e-01,  1.47687551e+09,  2.13740800e+08,\n",
       "        -1.43368540e-02,  1.53586280e-01],\n",
       "       [ 1.42556995e-01,  1.48559004e-01,  1.41289994e-01,\n",
       "         1.44470006e-01,  9.61074557e+08,  1.37007901e+08,\n",
       "         1.27088710e-02,  1.14973180e-01],\n",
       "       [ 1.44455999e-01,  1.44997001e-01,  1.39880002e-01,\n",
       "         1.43209994e-01,  8.84305263e+08,  1.27743200e+08,\n",
       "        -8.72161900e-03,  1.07060620e-01],\n",
       "       [ 1.43184006e-01,  1.47220001e-01,  1.37171999e-01,\n",
       "         1.37825996e-01,  1.05513695e+09,  1.51078736e+08,\n",
       "        -3.75951290e-02,  8.39072810e-02],\n",
       "       [ 1.38903007e-01,  1.48558006e-01,  1.37088001e-01,\n",
       "         1.46452993e-01,  1.04739913e+09,  1.45486889e+08,\n",
       "         5.42784860e-02,  1.46417220e-01],\n",
       "       [ 1.46412998e-01,  1.55312002e-01,  1.42008007e-01,\n",
       "         1.48590997e-01,  2.25350957e+09,  3.29943093e+08,\n",
       "         1.45985660e-02,  9.08316200e-02],\n",
       "       [ 1.38070002e-01,  1.42608002e-01,  1.37067005e-01,\n",
       "         1.40080005e-01,  8.90728707e+08,  1.22982914e+08,\n",
       "         1.45137280e-02,  1.19920160e-01],\n",
       "       [ 1.40053004e-01,  1.46632999e-01,  1.38100997e-01,\n",
       "         1.43920004e-01,  1.75906776e+09,  2.46362724e+08,\n",
       "         2.74129020e-02,  1.67889080e-01],\n",
       "       [ 1.43916994e-01,  1.49287000e-01,  1.42766997e-01,\n",
       "         1.46026000e-01,  1.14038209e+09,  1.64120362e+08,\n",
       "         1.46331010e-02,  1.15242019e-01],\n",
       "       [ 1.46017000e-01,  1.47810996e-01,  1.42093003e-01,\n",
       "         1.43711999e-01,  5.84019179e+08,  8.52767285e+07,\n",
       "        -1.58465020e-02,  1.31267300e-01],\n",
       "       [ 1.43693000e-01,  1.44709006e-01,  1.38995007e-01,\n",
       "         1.39458999e-01,  6.36442285e+08,  9.14523013e+07,\n",
       "        -2.95939100e-02,  1.29466020e-01],\n",
       "       [ 1.39470994e-01,  1.40460998e-01,  1.34384006e-01,\n",
       "         1.40285999e-01,  9.09718484e+08,  1.26879342e+08,\n",
       "         5.93005500e-03,  1.41832680e-01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data and targets have to be of same length. Data length is 17 while target length is 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2460/299273272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_data_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeseriesGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mval_data_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeseriesGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_data_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeseriesGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, targets, length, sampling_rate, stride, start_index, end_index, shuffle, reverse, batch_size)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             raise ValueError('Data and targets have to be' +\n\u001b[0m\u001b[0;32m    336\u001b[0m                              \u001b[1;34m' of same length. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m                              \u001b[1;34m'Data length is {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data and targets have to be of same length. Data length is 17 while target length is 0"
     ]
    }
   ],
   "source": [
    "train_data_gen = TimeseriesGenerator(X_train, y_train, length=look_back, batch_size=batch_size)\n",
    "val_data_gen = TimeseriesGenerator(X_val, y_val, length=look_back, batch_size=batch_size)\n",
    "test_data_gen = TimeseriesGenerator(X_test, y_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(train_data_gen)):\n",
    "    x, y = train_data_gen[i]\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, input_shape=(look_back, n_feat), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(LSTM(32))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_lstm.fit_generator(train_data_gen,\n",
    "                                        steps_per_epoch=10,\n",
    "                                        epochs=20,\n",
    "                                        verbose=1,\n",
    "                                        validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_lstm.predict(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d2dc41cbfaf67ac4a91a427b68830b69dde48fe3ce74dedd3ecbeef6226b1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
