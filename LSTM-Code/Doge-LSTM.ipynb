{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>6259550</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>4246520</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>2231080</td>\n",
       "      <td>0.001201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>3288960</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>2481270</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-19</th>\n",
       "      <td>0.144141</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.140297</td>\n",
       "      <td>0.142665</td>\n",
       "      <td>679511647</td>\n",
       "      <td>0.142665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-20</th>\n",
       "      <td>0.146241</td>\n",
       "      <td>0.139595</td>\n",
       "      <td>0.142677</td>\n",
       "      <td>0.140878</td>\n",
       "      <td>1068542289</td>\n",
       "      <td>0.140878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-21</th>\n",
       "      <td>0.142448</td>\n",
       "      <td>0.135255</td>\n",
       "      <td>0.140868</td>\n",
       "      <td>0.136365</td>\n",
       "      <td>740549793</td>\n",
       "      <td>0.136365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-22</th>\n",
       "      <td>0.137908</td>\n",
       "      <td>0.134985</td>\n",
       "      <td>0.136357</td>\n",
       "      <td>0.136395</td>\n",
       "      <td>505251263</td>\n",
       "      <td>0.136395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-23</th>\n",
       "      <td>0.136409</td>\n",
       "      <td>0.133810</td>\n",
       "      <td>0.136404</td>\n",
       "      <td>0.135758</td>\n",
       "      <td>367663104</td>\n",
       "      <td>0.135758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1627 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low      Open     Close      Volume  Adj Close\n",
       "Date                                                                     \n",
       "2017-11-09  0.001415  0.001181  0.001207  0.001415     6259550   0.001415\n",
       "2017-11-10  0.001431  0.001125  0.001421  0.001163     4246520   0.001163\n",
       "2017-11-11  0.001257  0.001141  0.001146  0.001201     2231080   0.001201\n",
       "2017-11-12  0.001210  0.001002  0.001189  0.001038     3288960   0.001038\n",
       "2017-11-13  0.001212  0.001019  0.001046  0.001211     2481270   0.001211\n",
       "...              ...       ...       ...       ...         ...        ...\n",
       "2022-04-19  0.144141  0.139500  0.140297  0.142665   679511647   0.142665\n",
       "2022-04-20  0.146241  0.139595  0.142677  0.140878  1068542289   0.140878\n",
       "2022-04-21  0.142448  0.135255  0.140868  0.136365   740549793   0.136365\n",
       "2022-04-22  0.137908  0.134985  0.136357  0.136395   505251263   0.136395\n",
       "2022-04-23  0.136409  0.133810  0.136404  0.135758   367663104   0.135758\n",
       "\n",
       "[1627 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doge = web.DataReader('DOGE-USD', 'yahoo')\n",
    "doge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        High       Low      Open     Close      Volume  Adj Close  \\\n",
      "0   0.174406  0.168271  0.174406  0.170088   505900382   0.170088   \n",
      "1   0.138747  0.135565  0.137213  0.137541   383506507   0.137541   \n",
      "2   0.133649  0.127810  0.132998  0.129610   518193386   0.129610   \n",
      "3   0.148558  0.137088  0.138903  0.146453  1047399132   0.146453   \n",
      "4   0.172339  0.168128  0.170151  0.168803   541922892   0.168803   \n",
      "5   0.147592  0.137250  0.137523  0.147503   580740990   0.147503   \n",
      "6   0.129856  0.121544  0.129631  0.122591   650665594   0.122591   \n",
      "7   0.155312  0.142008  0.146413  0.148591  2253509569   0.148591   \n",
      "8   0.157354  0.144031  0.144379  0.148948  1581065491   0.148948   \n",
      "9   0.116231  0.110686  0.115080  0.111608   373430106   0.111608   \n",
      "10  0.142608  0.137067  0.138070  0.140080   890728707   0.140080   \n",
      "11  0.150132  0.143649  0.148869  0.146003   898042727   0.146003   \n",
      "12  0.118967  0.110817  0.111607  0.114048   822092169   0.114048   \n",
      "13  0.146633  0.138101  0.140053  0.143920  1759067761   0.143920   \n",
      "14  0.152199  0.145203  0.145996  0.151761   674961496   0.151761   \n",
      "15  0.114213  0.110937  0.114043  0.112784   400614617   0.112784   \n",
      "16  0.149287  0.142767  0.143917  0.146026  1140382087   0.146026   \n",
      "17  0.151824  0.146771  0.151779  0.149095   505588732   0.149095   \n",
      "18  0.116908  0.112364  0.112779  0.116908   537170937   0.116908   \n",
      "19  0.147811  0.142093  0.146017  0.143712   584019179   0.143712   \n",
      "20  0.149889  0.138071  0.149050  0.138552   721382126   0.138552   \n",
      "21  0.118710  0.116281  0.116907  0.116502   412838814   0.116502   \n",
      "22  0.144709  0.138995  0.143693  0.139459   636442285   0.139459   \n",
      "23  0.142097  0.136960  0.138594  0.138768   563817289   0.138768   \n",
      "24  0.119375  0.114568  0.116490  0.119306   410862503   0.119306   \n",
      "25  0.140461  0.134384  0.139471  0.140286   909718484   0.140286   \n",
      "26  0.145906  0.138751  0.138764  0.141206   655782652   0.141206   \n",
      "27  0.124573  0.118530  0.119278  0.123569   628081786   0.123569   \n",
      "28  0.144141  0.139500  0.140297  0.142665   679511647   0.142665   \n",
      "29  0.141197  0.135852  0.141197  0.136868   490138547   0.136868   \n",
      "30  0.123919  0.117991  0.123579  0.119154   428111799   0.119154   \n",
      "31  0.146241  0.139595  0.142677  0.140878  1068542289   0.140878   \n",
      "32  0.141345  0.128246  0.136838  0.128490   913773124   0.128490   \n",
      "33  0.121332  0.118306  0.119146  0.119339   439486516   0.119339   \n",
      "34  0.142448  0.135255  0.140868  0.136365   740549793   0.136365   \n",
      "35  0.131696  0.125365  0.128488  0.131553   711967119   0.131553   \n",
      "36  0.125350  0.119014  0.119333  0.122481   610507111   0.122481   \n",
      "37  0.137908  0.134985  0.136357  0.136395   505251263   0.136395   \n",
      "38  0.135337  0.127846  0.131561  0.127846   587472906   0.127846   \n",
      "39  0.130713  0.121361  0.122487  0.129727   998922753   0.129727   \n",
      "40  0.136409  0.133810  0.136404  0.135887   368853856   0.135887   \n",
      "41  0.127851  0.109555  0.127821  0.123813  2046477370   0.123813   \n",
      "42  0.140605  0.128455  0.129722  0.136550  2017926806   0.136550   \n",
      "43  0.128181  0.120983  0.123843  0.127576   805161073   0.127576   \n",
      "44  0.137275  0.128782  0.136603  0.131013   882486375   0.131013   \n",
      "45  0.130071  0.126199  0.127568  0.127647   535575654   0.127647   \n",
      "46  0.136495  0.129878  0.131010  0.135868   610401998   0.135868   \n",
      "47  0.128235  0.122053  0.127639  0.123111   592809151   0.123111   \n",
      "48  0.144858  0.135703  0.135900  0.144732  1445019558   0.144732   \n",
      "49  0.134479  0.121954  0.123118  0.133156   765755924   0.133156   \n",
      "50  0.152737  0.142457  0.144725  0.142657  1476875507   0.142657   \n",
      "51  0.148559  0.141290  0.142557  0.144470   961074557   0.144470   \n",
      "52  0.144997  0.139880  0.144456  0.143210   884305263   0.143210   \n",
      "53  0.147220  0.137172  0.143184  0.137826  1055136949   0.137826   \n",
      "\n",
      "    Polarity Score  \n",
      "0         0.095867  \n",
      "1         0.146020  \n",
      "2         0.138143  \n",
      "3         0.146417  \n",
      "4         0.071015  \n",
      "5         0.096342  \n",
      "6         0.085107  \n",
      "7         0.090832  \n",
      "8         0.113200  \n",
      "9         0.111060  \n",
      "10        0.119920  \n",
      "11        0.367391  \n",
      "12        0.075841  \n",
      "13        0.167889  \n",
      "14        0.150535  \n",
      "15        0.100922  \n",
      "16        0.115242  \n",
      "17        0.010105  \n",
      "18        0.076036  \n",
      "19        0.131267  \n",
      "20        0.232539  \n",
      "21        0.133072  \n",
      "22        0.129466  \n",
      "23        0.245144  \n",
      "24        0.089275  \n",
      "25        0.141833  \n",
      "26        0.000168  \n",
      "27        0.223525  \n",
      "28        0.141011  \n",
      "29        0.219473  \n",
      "30        0.110555  \n",
      "31        0.127655  \n",
      "32        0.135519  \n",
      "33        0.115944  \n",
      "34        0.131129  \n",
      "35        0.112503  \n",
      "36        0.000000  \n",
      "37        0.112926  \n",
      "38        0.153502  \n",
      "39        0.140484  \n",
      "40        0.121865  \n",
      "41        0.109284  \n",
      "42        0.117736  \n",
      "43        0.107181  \n",
      "44        0.161422  \n",
      "45        0.141459  \n",
      "46        0.227658  \n",
      "47        0.199485  \n",
      "48        0.169030  \n",
      "49        0.131502  \n",
      "50        0.153586  \n",
      "51        0.114973  \n",
      "52        0.107061  \n",
      "53        0.083907  \n"
     ]
    }
   ],
   "source": [
    "#lstm_data = np.genfromtxt('./sample_data/lstm.csv', delimiter=',', skip_header=True)\n",
    "lstm_data = read_csv('lstmdoge.csv')\n",
    "lstm_data = lstm_data.drop(['Date'], axis=1)\n",
    "print(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X = lstm_data.drop(['Close'], axis=1)\n",
    "lstm_data_y = lstm_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 5 # how many days to look back\n",
    "batch_size = 3 # size of batches used when training\n",
    "n_feat = 6 # number of features \n",
    "n_target = 2\n",
    "n_validation = 6\n",
    "n_test = 8\n",
    "n_train = lstm_data_X.shape[0] - n_validation - n_test - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_data_X_train = lstm_data_X.iloc[:30,:]\n",
    "#lstm_data_X_val = lstm_data_X.iloc[30:40,:]\n",
    "#lstm_data_X_test = lstm_data_X.iloc[40:52,:]\n",
    "\n",
    "#lstm_data_y_train = lstm_data_y.iloc[:30]\n",
    "#lstm_data_y_val = lstm_data_y.iloc[30:40]\n",
    "#lstm_data_y_test = lstm_data_y.iloc[40:52]\n",
    "# Convert to numpy arrays\n",
    "#X_train = lstm_data_X_train.to_numpy()\n",
    "#X_val = lstm_data_X_val.to_numpy()\n",
    "#X_test = lstm_data_X_test.to_numpy()\n",
    "#y_train = lstm_data_y_train.to_numpy()\n",
    "#y_val = lstm_data_y_val.to_numpy()\n",
    "#y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X_train = lstm_data_X.iloc[:n_train,:]\n",
    "lstm_data_X_val = lstm_data_X.iloc[n_train:n_train + n_validation,:]\n",
    "lstm_data_X_test = lstm_data_X.iloc[n_train + n_validation:n_train + n_validation + n_test,:]\n",
    "\n",
    "lstm_data_y_train = lstm_data_y.iloc[:n_train]\n",
    "lstm_data_y_val = lstm_data_y.iloc[n_train:n_train + n_validation]\n",
    "lstm_data_y_test = lstm_data_y.iloc[n_train + n_validation:n_train + n_validation + n_test]\n",
    "# Convert to numpy arrays\n",
    "X_train = lstm_data_X_train.to_numpy()\n",
    "X_val = lstm_data_X_val.to_numpy()\n",
    "X_test = lstm_data_X_test.to_numpy()\n",
    "y_train = lstm_data_y_train.to_numpy()\n",
    "y_val = lstm_data_y_val.to_numpy()\n",
    "y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30070999e-01, 1.26199007e-01, 1.27568007e-01, 5.35575654e+08,\n",
       "        1.27646998e-01, 1.41458700e-01],\n",
       "       [1.36494994e-01, 1.29877999e-01, 1.31009996e-01, 6.10401998e+08,\n",
       "        1.35867998e-01, 2.27658000e-01],\n",
       "       [1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "        1.23111002e-01, 1.99485454e-01],\n",
       "       [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "        1.44731998e-01, 1.69029840e-01],\n",
       "       [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "        1.33156002e-01, 1.31502325e-01],\n",
       "       [1.52737007e-01, 1.42456993e-01, 1.44724995e-01, 1.47687551e+09,\n",
       "        1.42656997e-01, 1.53586280e-01],\n",
       "       [1.48559004e-01, 1.41289994e-01, 1.42556995e-01, 9.61074557e+08,\n",
       "        1.44470006e-01, 1.14973180e-01],\n",
       "       [1.44997001e-01, 1.39880002e-01, 1.44455999e-01, 8.84305263e+08,\n",
       "        1.43209994e-01, 1.07060620e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.127647  , 0.135868  , 0.123111  , 0.144732  , 0.133156  ,\n",
       "       0.142657  , 0.14447001, 0.14320999])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = TimeseriesGenerator(X_train, y_train, length=look_back, batch_size=batch_size)\n",
    "val_data_gen = TimeseriesGenerator(X_val, y_val, length=look_back, batch_size=batch_size)\n",
    "test_data_gen = TimeseriesGenerator(X_test, y_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(1, 5, 6) (1,)\n"
     ]
    }
   ],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(train_data_gen)):\n",
    "    x, y = train_data_gen[i]\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 5, 32)             4992      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 32)             0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,345\n",
      "Trainable params: 13,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, input_shape=(look_back, n_feat), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(LSTM(32))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_18704/192094070.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model_lstm.fit_generator(train_data_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 105ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 9.0681e-04 - val_mse: 9.0681e-04\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 5.8566e-04 - val_mse: 5.8566e-04\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 4.1337e-05 - val_mse: 4.1337e-05\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 1.8904e-04 - val_mse: 1.8904e-04\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 9.1611e-04 - val_mse: 9.1611e-04\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 6.4626e-04 - val_mse: 6.4626e-04\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 2.6118e-04 - val_mse: 2.6118e-04\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 7.4274e-04 - val_mse: 7.4274e-04\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 1.0032e-04 - val_mse: 1.0032e-04\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 2.7714e-04 - val_mse: 2.7714e-04\n"
     ]
    }
   ],
   "source": [
    "hist = model_lstm.fit_generator(train_data_gen,\n",
    "                                        steps_per_epoch=10,\n",
    "                                        epochs=20,\n",
    "                                        verbose=1,\n",
    "                                        validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_lstm.predict(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1.30070999e-01, 1.26199007e-01, 1.27568007e-01, 5.35575654e+08,\n",
       "          1.27646998e-01, 1.41458700e-01],\n",
       "         [1.36494994e-01, 1.29877999e-01, 1.31009996e-01, 6.10401998e+08,\n",
       "          1.35867998e-01, 2.27658000e-01],\n",
       "         [1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "          1.23111002e-01, 1.99485454e-01],\n",
       "         [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "          1.44731998e-01, 1.69029840e-01],\n",
       "         [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "          1.33156002e-01, 1.31502325e-01]],\n",
       " \n",
       "        [[1.36494994e-01, 1.29877999e-01, 1.31009996e-01, 6.10401998e+08,\n",
       "          1.35867998e-01, 2.27658000e-01],\n",
       "         [1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "          1.23111002e-01, 1.99485454e-01],\n",
       "         [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "          1.44731998e-01, 1.69029840e-01],\n",
       "         [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "          1.33156002e-01, 1.31502325e-01],\n",
       "         [1.52737007e-01, 1.42456993e-01, 1.44724995e-01, 1.47687551e+09,\n",
       "          1.42656997e-01, 1.53586280e-01]],\n",
       " \n",
       "        [[1.28234997e-01, 1.22052997e-01, 1.27638996e-01, 5.92809151e+08,\n",
       "          1.23111002e-01, 1.99485454e-01],\n",
       "         [1.44858003e-01, 1.35702997e-01, 1.35900006e-01, 1.44501956e+09,\n",
       "          1.44731998e-01, 1.69029840e-01],\n",
       "         [1.34479001e-01, 1.21954001e-01, 1.23117998e-01, 7.65755924e+08,\n",
       "          1.33156002e-01, 1.31502325e-01],\n",
       "         [1.52737007e-01, 1.42456993e-01, 1.44724995e-01, 1.47687551e+09,\n",
       "          1.42656997e-01, 1.53586280e-01],\n",
       "         [1.48559004e-01, 1.41289994e-01, 1.42556995e-01, 9.61074557e+08,\n",
       "          1.44470006e-01, 1.14973180e-01]]]),\n",
       " array([0.142657  , 0.14447001, 0.14320999]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1476606],\n",
       "       [0.1476606],\n",
       "       [0.1476606]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test[0:y_test.shape[0]-5], color = 'red', label = 'Real Dogecoin Price')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted Dogecoin Price')\n",
    "plt.title('Doge Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Doge Price')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d2dc41cbfaf67ac4a91a427b68830b69dde48fe3ce74dedd3ecbeef6226b1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
