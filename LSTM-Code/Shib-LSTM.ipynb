{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        High       Low      Open     Close      Volume  Adj Close  \\\n",
      "0   0.000034  0.000032  0.000034  0.000033   720676202   0.000033   \n",
      "1   0.000021  0.000020  0.000021  0.000021   421850042   0.000021   \n",
      "2   0.000026  0.000025  0.000026  0.000025   963213922   0.000025   \n",
      "3   0.000027  0.000026  0.000026  0.000027   918512393   0.000027   \n",
      "4   0.000033  0.000032  0.000033  0.000032   717218977   0.000032   \n",
      "5   0.000022  0.000021  0.000021  0.000022   609855710   0.000022   \n",
      "6   0.000025  0.000023  0.000025  0.000024   977852640   0.000024   \n",
      "7   0.000027  0.000026  0.000027  0.000026  1101356399   0.000026   \n",
      "8   0.000032  0.000029  0.000029  0.000030  2065365631   0.000030   \n",
      "9   0.000023  0.000021  0.000022  0.000022   660720467   0.000022   \n",
      "10  0.000028  0.000026  0.000027  0.000027  2032682825   0.000027   \n",
      "11  0.000031  0.000029  0.000030  0.000030  1558119657   0.000030   \n",
      "12  0.000022  0.000021  0.000022  0.000022   632243876   0.000022   \n",
      "13  0.000027  0.000025  0.000027  0.000026  1152162515   0.000026   \n",
      "14  0.000032  0.000030  0.000030  0.000031  1602354887   0.000031   \n",
      "15  0.000022  0.000021  0.000022  0.000022   640514222   0.000022   \n",
      "16  0.000026  0.000026  0.000026  0.000026   464520286   0.000026   \n",
      "17  0.000031  0.000030  0.000031  0.000031  1350071541   0.000031   \n",
      "18  0.000023  0.000022  0.000022  0.000023   841713079   0.000023   \n",
      "19  0.000026  0.000025  0.000026  0.000026   338664091   0.000026   \n",
      "20  0.000032  0.000028  0.000031  0.000028  2067544526   0.000028   \n",
      "21  0.000023  0.000022  0.000023  0.000022   594487997   0.000022   \n",
      "22  0.000026  0.000025  0.000026  0.000025   420838842   0.000025   \n",
      "23  0.000030  0.000028  0.000028  0.000028  1458694142   0.000028   \n",
      "24  0.000023  0.000022  0.000022  0.000022   696479699   0.000022   \n",
      "25  0.000025  0.000024  0.000025  0.000025   713137006   0.000025   \n",
      "26  0.000029  0.000027  0.000028  0.000028   929189862   0.000028   \n",
      "27  0.000025  0.000022  0.000022  0.000024  1912871449   0.000024   \n",
      "28  0.000026  0.000025  0.000025  0.000025   514266085   0.000025   \n",
      "29  0.000028  0.000025  0.000028  0.000026  1235841144   0.000026   \n",
      "30  0.000024  0.000023  0.000024  0.000023  1176567440   0.000023   \n",
      "31  0.000026  0.000025  0.000025  0.000025   628811523   0.000025   \n",
      "32  0.000027  0.000024  0.000026  0.000024  2001180593   0.000024   \n",
      "33  0.000023  0.000022  0.000023  0.000023   746003820   0.000023   \n",
      "34  0.000025  0.000024  0.000025  0.000024   520836111   0.000024   \n",
      "35  0.000025  0.000023  0.000024  0.000025  1524043647   0.000025   \n",
      "36  0.000024  0.000023  0.000023  0.000023   987790840   0.000023   \n",
      "37  0.000025  0.000024  0.000024  0.000024   431642746   0.000024   \n",
      "38  0.000027  0.000025  0.000025  0.000025  1728129985   0.000025   \n",
      "39  0.000025  0.000023  0.000023  0.000024  1272114432   0.000024   \n",
      "40  0.000025  0.000024  0.000024  0.000024   341880954   0.000024   \n",
      "41  0.000025  0.000021  0.000025  0.000024  3275038601   0.000024   \n",
      "42  0.000025  0.000024  0.000024  0.000025  1339708814   0.000025   \n",
      "43  0.000024  0.000024  0.000024  0.000024   305995904   0.000024   \n",
      "44  0.000025  0.000023  0.000024  0.000025  1740381961   0.000025   \n",
      "45  0.000025  0.000024  0.000025  0.000024   906531254   0.000024   \n",
      "46  0.000026  0.000024  0.000025  0.000024  1099351580   0.000024   \n",
      "47  0.000025  0.000024  0.000024  0.000024   472902729   0.000024   \n",
      "48  0.000025  0.000023  0.000024  0.000023  1217089606   0.000023   \n",
      "49  0.000026  0.000024  0.000024  0.000026   792774798   0.000026   \n",
      "50  0.000026  0.000023  0.000023  0.000026  1513953706   0.000026   \n",
      "51  0.000029  0.000025  0.000026  0.000026  3561607258   0.000026   \n",
      "52  0.000028  0.000026  0.000026  0.000027  2063838416   0.000027   \n",
      "53  0.000028  0.000026  0.000027  0.000027  1629913880   0.000027   \n",
      "54  0.000028  0.000026  0.000027  0.000026  1418516436   0.000026   \n",
      "\n",
      "    Polarity Score  \n",
      "0         0.095867  \n",
      "1         0.146020  \n",
      "2         0.138143  \n",
      "3         0.146417  \n",
      "4         0.071015  \n",
      "5         0.096342  \n",
      "6         0.085107  \n",
      "7         0.090832  \n",
      "8         0.113200  \n",
      "9         0.111060  \n",
      "10        0.119920  \n",
      "11        0.367391  \n",
      "12        0.075841  \n",
      "13        0.167889  \n",
      "14        0.150535  \n",
      "15        0.100922  \n",
      "16        0.115242  \n",
      "17        0.010105  \n",
      "18        0.076036  \n",
      "19        0.131267  \n",
      "20        0.232539  \n",
      "21        0.133072  \n",
      "22        0.129466  \n",
      "23        0.245144  \n",
      "24        0.089275  \n",
      "25        0.141833  \n",
      "26        0.000168  \n",
      "27        0.223525  \n",
      "28        0.141011  \n",
      "29        0.219473  \n",
      "30        0.110555  \n",
      "31        0.127655  \n",
      "32        0.135519  \n",
      "33        0.115944  \n",
      "34        0.131129  \n",
      "35        0.112503  \n",
      "36        0.000000  \n",
      "37        0.112926  \n",
      "38        0.153502  \n",
      "39        0.140484  \n",
      "40        0.121865  \n",
      "41        0.109284  \n",
      "42        0.117736  \n",
      "43        0.101390  \n",
      "44        0.107181  \n",
      "45        0.161422  \n",
      "46        0.141459  \n",
      "47        0.227658  \n",
      "48        0.199485  \n",
      "49        0.169030  \n",
      "50        0.131502  \n",
      "51        0.153586  \n",
      "52        0.114973  \n",
      "53        0.107061  \n",
      "54        0.083907  \n"
     ]
    }
   ],
   "source": [
    "#lstm_data = np.genfromtxt('./sample_data/lstm.csv', delimiter=',', skip_header=True)\n",
    "lstm_data = read_csv('lstmshib.csv')\n",
    "lstm_data = lstm_data.drop(['Date'], axis=1)\n",
    "print(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X = lstm_data.drop(['Close'], axis=1)\n",
    "lstm_data_y = lstm_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 5 # how many days to look back\n",
    "batch_size = 3 # size of batches used when training\n",
    "n_feat = 6 # number of features \n",
    "n_target = 2\n",
    "n_validation = 6\n",
    "n_test = 8\n",
    "n_train = lstm_data_X.shape[0] - n_validation - n_test - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X_train = lstm_data_X.iloc[:n_train,:]\n",
    "lstm_data_X_val = lstm_data_X.iloc[n_train:n_train + n_validation,:]\n",
    "lstm_data_X_test = lstm_data_X.iloc[n_train + n_validation:n_train + n_validation + n_test,:]\n",
    "\n",
    "lstm_data_y_train = lstm_data_y.iloc[:n_train]\n",
    "lstm_data_y_val = lstm_data_y.iloc[n_train:n_train + n_validation]\n",
    "lstm_data_y_test = lstm_data_y.iloc[n_train + n_validation:n_train + n_validation + n_test]\n",
    "# Convert to numpy arrays\n",
    "X_train = lstm_data_X_train.to_numpy()\n",
    "X_val = lstm_data_X_val.to_numpy()\n",
    "X_test = lstm_data_X_test.to_numpy()\n",
    "y_train = lstm_data_y_train.to_numpy()\n",
    "y_val = lstm_data_y_val.to_numpy()\n",
    "y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.59999997e-05, 2.40000008e-05, 2.49999994e-05, 1.09935158e+09,\n",
       "        2.40000008e-05, 1.41458700e-01],\n",
       "       [2.49999994e-05, 2.40000008e-05, 2.40000008e-05, 4.72902729e+08,\n",
       "        2.40000008e-05, 2.27658000e-01],\n",
       "       [2.49999994e-05, 2.30000005e-05, 2.40000008e-05, 1.21708961e+09,\n",
       "        2.30000005e-05, 1.99485454e-01],\n",
       "       [2.59999997e-05, 2.40000008e-05, 2.40000008e-05, 7.92774798e+08,\n",
       "        2.59999997e-05, 1.69029840e-01],\n",
       "       [2.59999997e-05, 2.30000005e-05, 2.30000005e-05, 1.51395371e+09,\n",
       "        2.59999997e-05, 1.31502325e-01],\n",
       "       [2.90000007e-05, 2.49999994e-05, 2.59999997e-05, 3.56160726e+09,\n",
       "        2.59999997e-05, 1.53586280e-01],\n",
       "       [2.80000004e-05, 2.59999997e-05, 2.59999997e-05, 2.06383842e+09,\n",
       "        2.70000000e-05, 1.14973180e-01],\n",
       "       [2.80000004e-05, 2.59999997e-05, 2.70000000e-05, 1.62991388e+09,\n",
       "        2.70000000e-05, 1.07060620e-01]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.40000008e-05, 2.40000008e-05, 2.30000005e-05, 2.59999997e-05,\n",
       "       2.59999997e-05, 2.59999997e-05, 2.70000000e-05, 2.70000000e-05])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = TimeseriesGenerator(X_train, y_train, length=look_back, batch_size=batch_size)\n",
    "val_data_gen = TimeseriesGenerator(X_val, y_val, length=look_back, batch_size=batch_size)\n",
    "test_data_gen = TimeseriesGenerator(X_test, y_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(2, 5, 6) (2,)\n"
     ]
    }
   ],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(train_data_gen)):\n",
    "    x, y = train_data_gen[i]\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 5, 32)             4992      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 5, 32)             0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,345\n",
      "Trainable params: 13,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, input_shape=(look_back, n_feat), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(LSTM(32))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_1520/192094070.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model_lstm.fit_generator(train_data_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 85ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 2.3004e-05 - val_mse: 2.3004e-05\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 6.7093e-05 - val_mse: 6.7093e-05\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.7165e-05 - val_mse: 3.7165e-05\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 5.7373e-06 - val_mse: 5.7373e-06\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 5.4146e-04 - val_mse: 5.4146e-04\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 4.4370e-11 - val_mse: 4.4370e-11\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 7.6461e-04 - val_mse: 7.6461e-04\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 4.4891e-07 - val_mse: 4.4891e-07\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 7.4522e-05 - val_mse: 7.4522e-05\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.9277e-04 - val_mse: 2.9277e-04\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.7279e-04 - val_mse: 1.7279e-04\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.2517e-04 - val_mse: 2.2517e-04\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 6.5542e-05 - val_mse: 6.5542e-05\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 3.7938e-06 - val_mse: 3.7938e-06\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 4.2004e-06 - val_mse: 4.2004e-06\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 7.4252e-04 - mse: 7.4252e-04 - val_loss: 5.1531e-05 - val_mse: 5.1531e-05\n"
     ]
    }
   ],
   "source": [
    "hist = model_lstm.fit_generator(train_data_gen,\n",
    "                                        steps_per_epoch=10,\n",
    "                                        epochs=20,\n",
    "                                        verbose=1,\n",
    "                                        validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002274B4DBC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pred = model_lstm.predict(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[2.59999997e-05, 2.40000008e-05, 2.49999994e-05, 1.09935158e+09,\n",
       "          2.40000008e-05, 1.41458700e-01],\n",
       "         [2.49999994e-05, 2.40000008e-05, 2.40000008e-05, 4.72902729e+08,\n",
       "          2.40000008e-05, 2.27658000e-01],\n",
       "         [2.49999994e-05, 2.30000005e-05, 2.40000008e-05, 1.21708961e+09,\n",
       "          2.30000005e-05, 1.99485454e-01],\n",
       "         [2.59999997e-05, 2.40000008e-05, 2.40000008e-05, 7.92774798e+08,\n",
       "          2.59999997e-05, 1.69029840e-01],\n",
       "         [2.59999997e-05, 2.30000005e-05, 2.30000005e-05, 1.51395371e+09,\n",
       "          2.59999997e-05, 1.31502325e-01]],\n",
       " \n",
       "        [[2.49999994e-05, 2.40000008e-05, 2.40000008e-05, 4.72902729e+08,\n",
       "          2.40000008e-05, 2.27658000e-01],\n",
       "         [2.49999994e-05, 2.30000005e-05, 2.40000008e-05, 1.21708961e+09,\n",
       "          2.30000005e-05, 1.99485454e-01],\n",
       "         [2.59999997e-05, 2.40000008e-05, 2.40000008e-05, 7.92774798e+08,\n",
       "          2.59999997e-05, 1.69029840e-01],\n",
       "         [2.59999997e-05, 2.30000005e-05, 2.30000005e-05, 1.51395371e+09,\n",
       "          2.59999997e-05, 1.31502325e-01],\n",
       "         [2.90000007e-05, 2.49999994e-05, 2.59999997e-05, 3.56160726e+09,\n",
       "          2.59999997e-05, 1.53586280e-01]],\n",
       " \n",
       "        [[2.49999994e-05, 2.30000005e-05, 2.40000008e-05, 1.21708961e+09,\n",
       "          2.30000005e-05, 1.99485454e-01],\n",
       "         [2.59999997e-05, 2.40000008e-05, 2.40000008e-05, 7.92774798e+08,\n",
       "          2.59999997e-05, 1.69029840e-01],\n",
       "         [2.59999997e-05, 2.30000005e-05, 2.30000005e-05, 1.51395371e+09,\n",
       "          2.59999997e-05, 1.31502325e-01],\n",
       "         [2.90000007e-05, 2.49999994e-05, 2.59999997e-05, 3.56160726e+09,\n",
       "          2.59999997e-05, 1.53586280e-01],\n",
       "         [2.80000004e-05, 2.59999997e-05, 2.59999997e-05, 2.06383842e+09,\n",
       "          2.70000000e-05, 1.14973180e-01]]]),\n",
       " array([2.59999997e-05, 2.70000000e-05, 2.70000000e-05]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00720249],\n",
       "       [0.00720249],\n",
       "       [0.00720249]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test[0:y_test.shape[0]-5], color = 'red', label = 'Real SHIBAPrice')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted SHIBA Price')\n",
    "plt.title('SHIBA Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('SHIBA Price')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d2dc41cbfaf67ac4a91a427b68830b69dde48fe3ce74dedd3ecbeef6226b1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
