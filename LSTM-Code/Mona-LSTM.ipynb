{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>3.039360</td>\n",
       "      <td>2.840420</td>\n",
       "      <td>2.855220</td>\n",
       "      <td>2.967630</td>\n",
       "      <td>4630550</td>\n",
       "      <td>2.967630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>2.993850</td>\n",
       "      <td>2.606440</td>\n",
       "      <td>2.959770</td>\n",
       "      <td>2.616590</td>\n",
       "      <td>3069090</td>\n",
       "      <td>2.616590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>2.714720</td>\n",
       "      <td>2.520320</td>\n",
       "      <td>2.627440</td>\n",
       "      <td>2.597220</td>\n",
       "      <td>3258960</td>\n",
       "      <td>2.597220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>3.109670</td>\n",
       "      <td>2.173080</td>\n",
       "      <td>2.598040</td>\n",
       "      <td>2.817210</td>\n",
       "      <td>9822060</td>\n",
       "      <td>2.817210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>3.254420</td>\n",
       "      <td>2.666150</td>\n",
       "      <td>2.795100</td>\n",
       "      <td>2.895720</td>\n",
       "      <td>9818930</td>\n",
       "      <td>2.895720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-19</th>\n",
       "      <td>0.896073</td>\n",
       "      <td>0.883590</td>\n",
       "      <td>0.891385</td>\n",
       "      <td>0.889009</td>\n",
       "      <td>151928</td>\n",
       "      <td>0.889009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-20</th>\n",
       "      <td>0.898475</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.889078</td>\n",
       "      <td>0.892699</td>\n",
       "      <td>192726</td>\n",
       "      <td>0.892699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-21</th>\n",
       "      <td>0.902868</td>\n",
       "      <td>0.879381</td>\n",
       "      <td>0.892625</td>\n",
       "      <td>0.881785</td>\n",
       "      <td>167541</td>\n",
       "      <td>0.881785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-22</th>\n",
       "      <td>0.883211</td>\n",
       "      <td>0.869527</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.878945</td>\n",
       "      <td>186793</td>\n",
       "      <td>0.878945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-23</th>\n",
       "      <td>0.885584</td>\n",
       "      <td>0.875964</td>\n",
       "      <td>0.879289</td>\n",
       "      <td>0.878712</td>\n",
       "      <td>147486</td>\n",
       "      <td>0.878712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1627 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low      Open     Close   Volume  Adj Close\n",
       "Date                                                                  \n",
       "2017-11-09  3.039360  2.840420  2.855220  2.967630  4630550   2.967630\n",
       "2017-11-10  2.993850  2.606440  2.959770  2.616590  3069090   2.616590\n",
       "2017-11-11  2.714720  2.520320  2.627440  2.597220  3258960   2.597220\n",
       "2017-11-12  3.109670  2.173080  2.598040  2.817210  9822060   2.817210\n",
       "2017-11-13  3.254420  2.666150  2.795100  2.895720  9818930   2.895720\n",
       "...              ...       ...       ...       ...      ...        ...\n",
       "2022-04-19  0.896073  0.883590  0.891385  0.889009   151928   0.889009\n",
       "2022-04-20  0.898475  0.882716  0.889078  0.892699   192726   0.892699\n",
       "2022-04-21  0.902868  0.879381  0.892625  0.881785   167541   0.881785\n",
       "2022-04-22  0.883211  0.869527  0.881720  0.878945   186793   0.878945\n",
       "2022-04-23  0.885584  0.875964  0.879289  0.878712   147486   0.878712\n",
       "\n",
       "[1627 rows x 6 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doge = web.DataReader('MONA-USD', 'yahoo')\n",
    "doge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        High       Low      Open     Close   Volume  Adj Close  Polarity Score\n",
      "0   1.241455  1.182781  1.236694  1.184539  1251855   1.184539        0.095867\n",
      "1   1.054188  1.000561  1.016678  1.008785   467346   1.008785        0.146020\n",
      "2   1.022445  0.989817  1.014940  0.996675   304333   0.996675        0.138143\n",
      "3   0.978820  0.965322  0.970673  0.972663   205397   0.972663        0.146417\n",
      "4   1.197341  1.177413  1.184803  1.184319   696471   1.184319        0.071015\n",
      "5   1.056811  1.008147  1.008871  1.051372   424532   1.051372        0.096342\n",
      "6   0.998576  0.970002  0.996708  0.982647   381357   0.982647        0.085107\n",
      "7   0.972628  0.955275  0.972628  0.965510   194245   0.965510        0.090832\n",
      "8   1.060776  1.041301  1.044525  1.055757   490092   1.055757        0.113200\n",
      "9   0.947661  0.934597  0.945077  0.936507   138229   0.936507        0.111060\n",
      "10  0.922446  0.893750  0.896942  0.921192   231487   0.921192        0.119920\n",
      "11  1.055742  1.021811  1.055726  1.034679   205570   1.034679        0.367391\n",
      "12  0.942785  0.933064  0.936504  0.939886   209986   0.939886        0.075841\n",
      "13  0.926987  0.895919  0.921091  0.896641   180988   0.896641        0.167889\n",
      "14  1.055246  1.022037  1.034578  1.053187   334767   1.053187        0.150535\n",
      "15  0.941809  0.931012  0.939891  0.938026   124396   0.938026        0.100922\n",
      "16  0.909872  0.896238  0.896737  0.909659   174450   0.909659        0.115242\n",
      "17  1.060616  1.035437  1.053166  1.049737   234412   1.049737        0.010105\n",
      "18  0.955998  0.934087  0.938009  0.947942   259295   0.947942        0.076036\n",
      "19  0.915845  0.898617  0.909633  0.900707   157344   0.900707        0.131267\n",
      "20  1.053838  1.017398  1.049745  1.019293   302457   1.019293        0.232539\n",
      "21  0.951459  0.938095  0.947940  0.948282   228895   0.948282        0.133072\n",
      "22  0.910478  0.897731  0.900560  0.898357    94190   0.898357        0.129466\n",
      "23  1.043297  0.999210  1.019312  1.007575   353211   1.007575        0.245144\n",
      "24  0.949749  0.931936  0.948250  0.941657   210373   0.941657        0.089275\n",
      "25  0.901525  0.878735  0.898389  0.891354   256523   0.891354        0.141833\n",
      "26  1.016447  0.986993  1.007664  1.006427   271839   1.006427        0.000168\n",
      "27  0.951966  0.938638  0.941657  0.947400   300176   0.947400        0.223525\n",
      "28  0.896073  0.883590  0.891385  0.889009   151928   0.889009        0.141011\n",
      "29  1.010323  0.964393  1.006419  0.998416   498230   0.998416        0.219473\n",
      "30  0.955283  0.933657  0.947404  0.941641   364295   0.941641        0.110555\n",
      "31  0.898475  0.882716  0.889078  0.892699   192726   0.892699        0.127655\n",
      "32  1.011017  0.974942  0.998303  0.977677   340243   0.977677        0.135519\n",
      "33  0.959084  0.938348  0.941660  0.948626   353478   0.948626        0.115944\n",
      "34  0.902868  0.879381  0.892625  0.881785   167541   0.881785        0.131129\n",
      "35  0.998481  0.962618  0.977620  0.995520   248098   0.995520        0.112503\n",
      "36  0.967868  0.942172  0.948642  0.952501   677719   0.952501        0.000000\n",
      "37  0.883211  0.869527  0.881720  0.878945   186793   0.878945        0.112926\n",
      "38  1.005631  0.988088  0.995582  0.990285   178773   0.990285        0.153502\n",
      "39  0.975304  0.951171  0.952623  0.974095   454355   0.974095        0.140484\n",
      "40  0.885584  0.875964  0.879289  0.877555   151602   0.877555        0.121865\n",
      "41  0.990445  0.939360  0.990238  0.959027   664471   0.959027        0.109284\n",
      "42  0.981590  0.953585  0.974083  0.954097   489069   0.954097        0.117736\n",
      "43  1.006944  0.956165  0.959106  1.000859   823896   1.000859        0.107181\n",
      "44  0.984148  0.950223  0.954149  0.955652   671498   0.955652        0.161422\n",
      "45  1.007445  0.979285  1.000863  0.986811   277347   0.986811        0.141459\n",
      "46  1.001894  0.954017  0.955664  0.985116   853500   0.985116        0.227658\n",
      "47  1.015193  0.974043  0.986870  0.974151   457800   0.974151        0.199485\n",
      "48  1.008562  0.978913  0.985115  1.008550   463497   1.008550        0.169030\n",
      "49  1.018426  0.971316  0.974134  1.014812   371633   1.014812        0.131502\n",
      "50  1.030112  0.999376  1.008556  1.002952   781560   1.002952        0.153586\n",
      "51  1.020251  0.994093  1.002975  0.999426   565050   0.999426        0.114973\n",
      "52  1.002289  0.977300  0.999467  0.985450   564840   0.985450        0.107061\n",
      "53  1.010521  0.969276  0.985485  0.979062   585842   0.979062        0.083907\n"
     ]
    }
   ],
   "source": [
    "#lstm_data = np.genfromtxt('./sample_data/lstm.csv', delimiter=',', skip_header=True)\n",
    "lstm_data = read_csv('lstmsmona.csv')\n",
    "lstm_data = lstm_data.drop(['Date'], axis=1)\n",
    "print(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X = lstm_data.drop(['Close'], axis=1)\n",
    "lstm_data_y = lstm_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 5 # how many days to look back\n",
    "batch_size = 3 # size of batches used when training\n",
    "n_feat = 6 # number of features \n",
    "n_target = 2\n",
    "n_validation = 6\n",
    "n_test = 8\n",
    "n_train = lstm_data_X.shape[0] - n_validation - n_test - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_data_X_train = lstm_data_X.iloc[:30,:]\n",
    "#lstm_data_X_val = lstm_data_X.iloc[30:40,:]\n",
    "#lstm_data_X_test = lstm_data_X.iloc[40:52,:]\n",
    "\n",
    "#lstm_data_y_train = lstm_data_y.iloc[:30]\n",
    "#lstm_data_y_val = lstm_data_y.iloc[30:40]\n",
    "#lstm_data_y_test = lstm_data_y.iloc[40:52]\n",
    "# Convert to numpy arrays\n",
    "#X_train = lstm_data_X_train.to_numpy()\n",
    "#X_val = lstm_data_X_val.to_numpy()\n",
    "#X_test = lstm_data_X_test.to_numpy()\n",
    "#y_train = lstm_data_y_train.to_numpy()\n",
    "#y_val = lstm_data_y_val.to_numpy()\n",
    "#y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X_train = lstm_data_X.iloc[:n_train,:]\n",
    "lstm_data_X_val = lstm_data_X.iloc[n_train:n_train + n_validation,:]\n",
    "lstm_data_X_test = lstm_data_X.iloc[n_train + n_validation:n_train + n_validation + n_test,:]\n",
    "\n",
    "lstm_data_y_train = lstm_data_y.iloc[:n_train]\n",
    "lstm_data_y_val = lstm_data_y.iloc[n_train:n_train + n_validation]\n",
    "lstm_data_y_test = lstm_data_y.iloc[n_train + n_validation:n_train + n_validation + n_test]\n",
    "# Convert to numpy arrays\n",
    "X_train = lstm_data_X_train.to_numpy()\n",
    "X_val = lstm_data_X_val.to_numpy()\n",
    "X_test = lstm_data_X_test.to_numpy()\n",
    "y_train = lstm_data_y_train.to_numpy()\n",
    "y_val = lstm_data_y_val.to_numpy()\n",
    "y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00744498e+00, 9.79285002e-01, 1.00086296e+00, 2.77347000e+05,\n",
       "        9.86810982e-01, 1.41458700e-01],\n",
       "       [1.00189400e+00, 9.54016984e-01, 9.55663979e-01, 8.53500000e+05,\n",
       "        9.85116005e-01, 2.27658000e-01],\n",
       "       [1.01519299e+00, 9.74043012e-01, 9.86869991e-01, 4.57800000e+05,\n",
       "        9.74151015e-01, 1.99485454e-01],\n",
       "       [1.00856197e+00, 9.78913009e-01, 9.85114992e-01, 4.63497000e+05,\n",
       "        1.00855005e+00, 1.69029840e-01],\n",
       "       [1.01842594e+00, 9.71315980e-01, 9.74134028e-01, 3.71633000e+05,\n",
       "        1.01481199e+00, 1.31502325e-01],\n",
       "       [1.03011203e+00, 9.99375999e-01, 1.00855601e+00, 7.81560000e+05,\n",
       "        1.00295198e+00, 1.53586280e-01],\n",
       "       [1.02025104e+00, 9.94093001e-01, 1.00297499e+00, 5.65050000e+05,\n",
       "        9.99426007e-01, 1.14973180e-01],\n",
       "       [1.00228906e+00, 9.77299988e-01, 9.99467015e-01, 5.64840000e+05,\n",
       "        9.85450029e-01, 1.07060620e-01]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98681098, 0.985116  , 0.97415102, 1.00855005, 1.01481199,\n",
       "       1.00295198, 0.99942601, 0.98545003])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = TimeseriesGenerator(X_train, y_train, length=look_back, batch_size=batch_size)\n",
    "val_data_gen = TimeseriesGenerator(X_val, y_val, length=look_back, batch_size=batch_size)\n",
    "test_data_gen = TimeseriesGenerator(X_test, y_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(1, 5, 6) (1,)\n"
     ]
    }
   ],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(train_data_gen)):\n",
    "    x, y = train_data_gen[i]\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 5, 32)             4992      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 5, 32)             0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,345\n",
      "Trainable params: 13,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, input_shape=(look_back, n_feat), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(LSTM(32))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_23816/192094070.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model_lstm.fit_generator(train_data_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 86ms/step - loss: 0.7137 - mse: 0.7137 - val_loss: 0.2729 - val_mse: 0.2729\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1482 - mse: 0.1482 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 2.8069e-04 - val_mse: 2.8069e-04\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 4.6550e-04 - val_mse: 4.6550e-04\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 2.4927e-04 - val_mse: 2.4927e-04\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 7.4436e-04 - val_mse: 7.4436e-04\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 3.3986e-04 - val_mse: 3.3986e-04\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 6.7612e-05 - val_mse: 6.7612e-05\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 7.0383e-04 - val_mse: 7.0383e-04\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 1.3132e-04 - val_mse: 1.3132e-04\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 1.3843e-05 - val_mse: 1.3843e-05\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 5.1176e-07 - val_mse: 5.1176e-07\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 6.5963e-05 - val_mse: 6.5963e-05\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 6.4062e-06 - val_mse: 6.4062e-06\n"
     ]
    }
   ],
   "source": [
    "hist = model_lstm.fit_generator(train_data_gen,\n",
    "                                        steps_per_epoch=10,\n",
    "                                        epochs=20,\n",
    "                                        verbose=1,\n",
    "                                        validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000139DB69E430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pred = model_lstm.predict(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1.00744498e+00, 9.79285002e-01, 1.00086296e+00, 2.77347000e+05,\n",
       "          9.86810982e-01, 1.41458700e-01],\n",
       "         [1.00189400e+00, 9.54016984e-01, 9.55663979e-01, 8.53500000e+05,\n",
       "          9.85116005e-01, 2.27658000e-01],\n",
       "         [1.01519299e+00, 9.74043012e-01, 9.86869991e-01, 4.57800000e+05,\n",
       "          9.74151015e-01, 1.99485454e-01],\n",
       "         [1.00856197e+00, 9.78913009e-01, 9.85114992e-01, 4.63497000e+05,\n",
       "          1.00855005e+00, 1.69029840e-01],\n",
       "         [1.01842594e+00, 9.71315980e-01, 9.74134028e-01, 3.71633000e+05,\n",
       "          1.01481199e+00, 1.31502325e-01]],\n",
       " \n",
       "        [[1.00189400e+00, 9.54016984e-01, 9.55663979e-01, 8.53500000e+05,\n",
       "          9.85116005e-01, 2.27658000e-01],\n",
       "         [1.01519299e+00, 9.74043012e-01, 9.86869991e-01, 4.57800000e+05,\n",
       "          9.74151015e-01, 1.99485454e-01],\n",
       "         [1.00856197e+00, 9.78913009e-01, 9.85114992e-01, 4.63497000e+05,\n",
       "          1.00855005e+00, 1.69029840e-01],\n",
       "         [1.01842594e+00, 9.71315980e-01, 9.74134028e-01, 3.71633000e+05,\n",
       "          1.01481199e+00, 1.31502325e-01],\n",
       "         [1.03011203e+00, 9.99375999e-01, 1.00855601e+00, 7.81560000e+05,\n",
       "          1.00295198e+00, 1.53586280e-01]],\n",
       " \n",
       "        [[1.01519299e+00, 9.74043012e-01, 9.86869991e-01, 4.57800000e+05,\n",
       "          9.74151015e-01, 1.99485454e-01],\n",
       "         [1.00856197e+00, 9.78913009e-01, 9.85114992e-01, 4.63497000e+05,\n",
       "          1.00855005e+00, 1.69029840e-01],\n",
       "         [1.01842594e+00, 9.71315980e-01, 9.74134028e-01, 3.71633000e+05,\n",
       "          1.01481199e+00, 1.31502325e-01],\n",
       "         [1.03011203e+00, 9.99375999e-01, 1.00855601e+00, 7.81560000e+05,\n",
       "          1.00295198e+00, 1.53586280e-01],\n",
       "         [1.02025104e+00, 9.94093001e-01, 1.00297499e+00, 5.65050000e+05,\n",
       "          9.99426007e-01, 1.14973180e-01]]]),\n",
       " array([1.00295198, 0.99942601, 0.98545003]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95312095],\n",
       "       [0.95312095],\n",
       "       [0.95312095]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAEWCAYAAAAuOkCvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo00lEQVR4nO3deZwV1Znw8d8jLog7y2RUNDAGF1Ah2JroiGPihkmUGDd0xogb5g0ajYnRZOZNjFnGJDpuQ+ISjHFiEHd04h7jiDFmgAREQBTFBYe8QTAIGlmf9497u+d209000Lerl9/387kfqs45VfWcrr7wcOpUVWQmkiRJalubFB2AJElSV2QSJkmSVACTMEmSpAKYhEmSJBXAJEySJKkAJmGSJEkFMAmT1OlExD9GxGNFx7E+IiIj4iPl5Rsi4v9u4H6WRcTftW50kqrBJEwSEfFaRKyIiN4Nyv9YTg76VZQdFBFPRsTSiFgSEQ9GxMCK+kPL2/y4wb6eiYhRDcpq216yjvgOjYg15QRjaUTMiYgzmmqfmbdn5pEt633LrG8MGyMzv5CZ32lBTE9FxNkNtt06M1+tRlySWpdJmKRa84BTalciYh+gR2WDiDgQeAyYCOwE9AemA79tMPryHnBaZfLWhNOBxcDnWxDf/2Tm1sC2wCXAzZXJX0WMm7ZgXxuqPcQgqZMwCZNU6z+onwydDtzWoM0Pgdsy89rMXJqZizPzX4DngMsq2v0FuBX4VlMHi4itgBOAMcCAiKhpSZBZcj/wDjAwIkZFxG8j4uqIWARcVi57puJYgyLi8YhYHBH/LyK+US7fJCIujYhXImJRRNwZET1bKYYtIuLKiHijfMwbImLLipgujogFEfE/EXFmg5/NrRHx3Yr1ERExLSLeLcc6PCK+BwwD/r08Ovfv5baVlzW3i4jbImJhRLweEf8SEZuU60aVRyevjIh3ImJeRBzdknMgqXWYhEmq9RywbUTsFRHdgJHAL2orI6IHcBBwVyPb3gkc0aDse8DxEbFHE8f7HLCsvL9HKSV961ROnI4DtgdmlIs/BrwKfKh83Mr22wBPAI9QGr37CPDrcvX5wGeBfyjXvQOMbaUYrgB2B4aUj7kz8M3y9sOBr1L6mQ0ADm/mWAdQSoYvLh/vEOC1zPxnYBJwXvkS5HmNbH49sB3wd+U+fh6ovIT6MWAO0JtSgj0uImJd/ZfUOkzCJFWqHQ07ApgNvFVR15PS3xkLGtluAaV/yOtk5p+AG4DLmzjW6cCEzFwN/BIYGRGbNRPbThHxF+BtSiNsp2XmnHLd/2Tm9Zm5KjP/2mC7zwB/ysyrMvOD8gje78t1XwD+OTPnZ+ZySqN5JzRzObFFMQAfAKOBL5dHC5cC36eU2AKcBPwsM1/IzPeoP4rY0FnALZn5eGauycy3MvPFZtoDUJFIf73c59eAq4DTKpq9npk3l8/Bz4EdKSWRktqA8xYkVfoP4GlKc70aXop8B1hD6R/qhknAjpQSk4Z+ALwSEYMrCyNiF+ATwNfLRROBm4BPA/c3Edv/ZGbfJurebKIcYBfglSbqPgzcFxFrKspWU0pE3mqkfUtj6ENpPt3UioGlALqVl3cCpla0f73J6EvxP9RMfVN6A5s12PfrlEbkav2pdiEz3y/HuvUGHEvSBnAkTFKdzHyd0gT9TwH3Nqh7D/gdcGIjm57E/17iq9xmEXAN0PBOv9Mo/f3zYET8idJlvO608JJkY6E3U/cmpctxTdUdnZnbV3y6Z2ZjCdj6xPA28FdgUMV+tytP6ofSyOEuFe13XUf8u7XgmA29DayklGhWHmdD+iapCkzCJDV0FvDJctLV0KXA6RHxpYjYJiJ2KE8gPxD4dhP7+zdKc8n2qig7vdx+SMXneOBTEdGrNTpR4T+BHSPiwvJk+W0i4mPluhuA70XEhwEiok9EjNjYA2bmGuBm4OqI+JvyvneOiKPKTe4ERkXEwPJcuyZvYADGAWdExGHluWg7R8Se5br/RxMJZvkS453l/m1T7uNFVMzzk1QskzBJ9WTmK5k5pYm6Z4CjKE2qX0Dp8tZHgYMz8+UmtnmX0qTvngAR8XFKozNjM/NPFZ8HgLlUPCajlfqzlNIct2MoXX57mdKlUIBrgQeAxyJiKaWbEz7W2H42wCWU+vNcRLxL6eaAPcoxPUxphPDJcpsnm4n/vylNpr8aWAL8F/87unUtpTls70TEdY1sfj6lx4W8CjxDae7dLRvbMUmtIzKbG82WJElSNTgSJkmSVICqJWERcUtE/DkiXmiiPiLiuoiYGxHPR8TQasUiSZLU3lRzJOxWYHgz9UdTekjhAErP0/lJFWORJElqV6qWhGXm05TeCdeUEZRef5KZ+RywfUTsWK14JEmS2pMiH9a6M/Ufbji/XLbW07gjYjSl0TK22mqr/fbcc8+GTSRJktqdqVOnvp2ZfRqr6xBPzM/Mmyg9TZuampqcMqXRu+clSZLalYho8o0YRSZhb1H/idF9aQ9Pcp41C35R8SzDynfZ1i43VmZ9+4ylvde3p1g6ev3G7isCunWDTTb53z8rl9dVtskm9fcrSetQZBL2AHBeRNxB6eGISzKzsRcDt62XX4YrrywtVz5DrXa5sbKGy5K6pspEbn0SuIZlrbGP1i7rTMc3WVY7UbUkLCLGA4cCvSNiPqXXcmwGkJk3UHoh7acoPS36fUpPhC7eiBGwYkXr7GtDkriOXt+eYuno9e0plvZe3xr7WrOm9Fm9eu3lapVtzD5Wrqx+TGsq32veybS3xLAjHr8tkuVOnjBXLQnLzGZfPZKlR/WPqdbx24WmLolIUkeQWfp0lMS0Pca0ciUsX17943dWlZf7q5EEjhkD//iPhXWvQ0zMlyQVoHYkYpNNio5E61LNZLnoJLiaMW22WaGnzSRMkqSOLgI29Z/0jsb/3kiSJBXAJEySJKkAjl02cOGFMG1a0VFIkqRqGzIErrmmuOM7EiZJklQAR8IaKDIjliRJXYcjYZIkSQUwCZMkSSqASZgkSVIBTMIkSZIKYBImSZJUAJMwSZKkApiESZIkFcAkTJIkqQAmYZIkSQUwCZMkSSqASZgkSVIBTMIkSZIKYBImSZJUAJMwSZKkApiESZIkFcAkTJIkqQAmYZIkSQUwCZMkSSqASZgkSVIBTMIkSZIKYBImSZJUAJMwSZKkApiESZIkFcAkTJIkqQAmYZIkSQUwCZMkSSqASZgkSVIBTMIkSZIKUNUkLCKGR8SciJgbEZc2Ur9rRPwmIv4YEc9HxKeqGY8kSVJ7UbUkLCK6AWOBo4GBwCkRMbBBs38B7szMjwIjgR9XKx5JkqT2pJojYQcAczPz1cxcAdwBjGjQJoFty8vbAf9TxXgkSZLajWomYTsDb1aszy+XVboM+KeImA88BJzf2I4iYnRETImIKQsXLqxGrJIkSW2q6In5pwC3ZmZf4FPAf0TEWjFl5k2ZWZOZNX369GnzICVJklpbNZOwt4BdKtb7lssqnQXcCZCZvwO6A72rGJMkSVK7UM0kbDIwICL6R8TmlCbeP9CgzRvAYQARsRelJMzrjZIkqdOrWhKWmauA84BHgdmU7oKcGRGXR8Sx5WZfAc6JiOnAeGBUZma1YpIkSWovNq3mzjPzIUoT7ivLvlmxPAv4+2rGIEmS1B4VPTFfkiSpSzIJkyRJKoBJmCRJUgFMwiRJkgpgEiZJklQAkzBJkqQCmIRJkiQVwCRMkiSpACZhkiRJBTAJkyRJKoBJmCRJUgFMwiRJkgpgEiZJklQAkzBJkqQCmIRJkiQVwCRMkiSpACZhkiRJBTAJkyRJKoBJmCRJUgFMwiRJkgpgEiZJklQAkzBJkqQCmIRJkiQVwCRMkiSpACZhkiRJBTAJkyRJKoBJmCRJUgFMwiRJkgpgEiZJklQAkzBJkqQCmIRJkiQVwCRMkiSpAOtMwiLiQxExLiIeLq8PjIizqh+aJElS59WSkbBbgUeBncrrLwEXVikeSZKkLqElSVjvzLwTWAOQmauA1S3ZeUQMj4g5ETE3Ii5tos1JETErImZGxC9bHLkkSVIHtmkL2rwXEb2ABIiIjwNL1rVRRHQDxgJHAPOByRHxQGbOqmgzAPg68PeZ+U5E/M0G9EGSJKnDaUkSdhHwALBbRPwW6AOc0ILtDgDmZuarABFxBzACmFXR5hxgbGa+A5CZf16P2CVJkjqsdSZhmfmHiPgHYA8ggDmZubIF+94ZeLNifT7wsQZtdgcoJ3fdgMsy85GGO4qI0cBogF133bUFh5YkSWrfWnJ35Bhg68ycmZkvAFtHxBdb6fibAgOAQ4FTgJsjYvuGjTLzpsysycyaPn36tNKhJUmSitOSifnnZOZfalfKlw7PacF2bwG7VKz3LZdVmg88kJkrM3MepTsvB7Rg35IkSR1aS5KwbhERtSvlCfebt2C7ycCAiOgfEZsDIynNLat0P6VRMCKiN6XLk6+2YN+SJEkdWksm5j8CTIiIG8vr55bLmpWZqyLiPErPGOsG3JKZMyPicmBKZj5QrjsyImZReuzFxZm5aEM6IkmS1JFEZjbfIGITSonXYeWix4GfZmaLnhXW2mpqanLKlClFHFqSJGm9RMTUzKxprK4ld0euAX5S/kiSJKkVNJmERcSdmXlSRMyg/KDWSpm5b1UjkyRJ6sSaGwm7oPznZ9oiEEmSpK6kySQsMxeU74S8NTM/0YYxSZIkdXrNPqKiPPl+TURs10bxSJIkdQkteUTFMmBGRDwOvFdbmJlfqlpUkiRJnVxLkrB7yx9JkiS1kmaTsIj4LNAHmJGZj7ZJRJIkSV1Ak3PCIuLHwJeBXsB3IuL/tllUkiRJnVxzI2GHAIMzc3VE9AAmAd9pm7AkSZI6t+bujlxR+2qizHwfiGbaSpIkaT00NxK2Z0Q8X14OYLfyegDpE/MlSZI2XHNJ2F5tFoUkSVIX09wT819vy0AkSZK6kmafmC9JkqTqMAmTJEkqwHonYRGxS0RcXI1gJEmSuooWJWER0ScivhgRk4CngA9VNSpJkqROrsmJ+RGxDfA54FRgd0rvj+yfmX3bKDZJkqROq7lHVPwZ+G/gX4BnMjMj4ri2CUuSJKlza+5y5NeBLYAfA1+PiN3aJiRJkqTOr8kkLDOvycyPAyPKRfcDO0XEJRGxe1sEJ0mS1Fmtc2J+Zr6amd/PzH2AGmA74KGqRyZJktSJrdcjKjLzhcz8RmZ+pFoBSZIkdQXN3R05D8jKoor1zEzniEmSJG2g5u6OrGmwvglwEvBV4I9Vi0iSJKkLaO4F3osAImIT4DTgYmAa8OnMnNUm0UmSJHVSzV2O3Aw4E/gy8Azw2cyc21aBSZIkdWbNXY6cB6wCrgHeAPaNiH1rKzPz3uqGJkmS1Hk1l4Q9QWki/uDyp1JSeo2RJEmSNkBzc8JGtWEckiRJXUqzzwmLiL0j4ucRMaX8+XlE7NNWwUmSJHVWTSZhETECuA/4L0oT9M8sL99brpMkSdIGam5O2OXAEZn5WkXZ8xHxJDCx/JEkSdIGaO5y5KYNEjAAymWbVSsgSZKkrqC5JGxVROzasDAiPkzp0RXrFBHDI2JORMyNiEubaXd8RGRENHxKvyRJUqfUXBL2LeCJiBgVEfuUP2cAjwHfXNeOI6IbMBY4GhgInBIRAxtptw1wAfD7DemAJElSR9RkEpaZ9wMnAp8Ebi1/PgmcVK5blwOAuZn5amauAO4AGpvQ/x3gB8AH6xG3JElSh9bcxHwyczrw+Q3c987AmxXr84GPVTaIiKHALpn5q4i4uKkdRcRoYDTArruudYVUkiSpw2nu3ZEPNLdhZh67MQcuvxj834BR62qbmTcBNwHU1NTkxhxXkiSpPWhuJOxASiNZ4ynN14r13PdbwC4V633LZbW2AfYGnooIgL8FHoiIYzNzynoeS5IkqUNpLgn7W+AI4BTgVOBXwPjMnNnCfU8GBkREf0rJ18jyfgDIzCVA79r1iHgK+KoJmCRJ6gqam5i/OjMfyczTgY8DcymNWp3Xkh1n5irgPOBRYDZwZ2bOjIjLI2KjLmVKkiR1dM1OzI+ILYBPUxoN6wdcR+lVRi2SmQ8BDzUoa/TxFpl5aEv3K0mS1NE1NzH/Nkpzth4Cvp2ZL7RZVJIkSZ1ccyNh/wS8R+lBql8qT56H0gT9zMxtqxybJElSp9VkEpaZzT1NX5IkSRvBREuSJKkAJmGSJEkFMAmTJEkqgEmYJElSAUzCJEmSCmASJkmSVACTMEmSpAKYhEmSJBXAJEySJKkAJmGSJEkFMAmTJEkqgEmYJElSAUzCJEmSCmASJkmSVACTMEmSpAKYhEmSJBXAJEySJKkAJmGSJEkFMAmTJEkqgEmYJElSAUzCJEmSCmASJkmSVACTMEmSpAKYhEmSJBXAJEySJKkAJmGSJEkFMAmTJEkqgEmYJElSAUzCJEmSCmASJkmSVACTMEmSpAJUNQmLiOERMSci5kbEpY3UXxQRsyLi+Yj4dUR8uJrxSJIktRdVS8IiohswFjgaGAicEhEDGzT7I1CTmfsCdwM/rFY8kiRJ7Uk1R8IOAOZm5quZuQK4AxhR2SAzf5OZ75dXnwP6VjEeSZKkdqOaSdjOwJsV6/PLZU05C3i4sYqIGB0RUyJiysKFC1sxREmSpGK0i4n5EfFPQA3wo8bqM/OmzKzJzJo+ffq0bXCSJElVsGkV9/0WsEvFet9yWT0RcTjwz8A/ZObyKsYjSZLUblRzJGwyMCAi+kfE5sBI4IHKBhHxUeBG4NjM/HMVY5EkSWpXqpaEZeYq4DzgUWA2cGdmzoyIyyPi2HKzHwFbA3dFxLSIeKCJ3UmSJHUq1bwcSWY+BDzUoOybFcuHV/P4kiRJ7VVVk7C2snLlSubPn88HH3xQdCjqgLp3707fvn3ZbLPNig5FktSFdIokbP78+WyzzTb069ePiCg6HHUgmcmiRYuYP38+/fv3LzocSVIX0i4eUbGxPvjgA3r16mUCpvUWEfTq1ctRVElSm+sUSRhgAqYN5u+OJKkInSYJkyRJ6khMwlpJt27dGDJkCHvvvTfHHHMMf/nLXzZoP7feeivnnXdeo+URwRNPPFFXdv/99xMR3H333QCsWLGCCy+8kI985CMMGDCAESNGMH/+/Lr2EcFXvvKVuvUrr7ySyy67rN5xhgwZwsiRI+uVjRo1iv79+zNkyBCGDh3K7373u0Zj/+Y3v1kvPkmS1DSTsFay5ZZbMm3aNF544QV69uzJ2LFjW/0Y++yzD3fccUfd+vjx4xk8eHDd+je+8Q2WLl3KnDlzePnll/nsZz/L5z73OTITgC222IJ7772Xt99+u9H9z549m9WrVzNp0iTee++9enU/+tGPmDZtGldccQXnnnvuWtuuXr2ayy+/nMMP96kjkiS1RKe4O7KeCy+EadNad59DhsA117S4+YEHHsjzzz8PwCuvvMKYMWNYuHAhPXr04Oabb2bPPffkwQcf5Lvf/S4rVqygV69e3H777XzoQx9qdr/Dhg1j0qRJrFy5kuXLlzN37lyGDBkCwPvvv8/PfvYz5s2bR7du3QA444wzuOWWW3jyySc57LDD2HTTTRk9ejRXX3013/ve99ba//jx4znttNOYPXs2EydO5NRTT12rzSGHHMLcuXMB6NevHyeffDKPP/44X/va13jkkUf4zGc+wwknnMDkyZO54IILeO+999hiiy349a9/TY8ePbj00kt56qmnWL58OWPGjGk0oZMkqStwJKyVrV69ml//+tcce2zppQCjR4/m+uuvZ+rUqVx55ZV88YtfBODggw/mueee449//CMjR47khz/84Tr3HREcfvjhPProo0ycOLHuGABz585l1113Zdttt623TU1NDTNnzqxbHzNmDLfffjtLlixZa/8TJkxg5MiRnHLKKYwfP77RGB588EH22WefuvVevXrxhz/8od4lzBUrVnDyySdz7bXXMn36dJ544gm23HJLxo0bx3bbbcfkyZOZPHkyN998M/PmzVtnvyVJ6ow630jYeoxYtaa//vWvDBkyhLfeeou99tqLI444gmXLlvHss89y4okn1rVbvrz0jvL58+dz8skns2DBAlasWNHiZ1SNHDmS6667jiVLlnDVVVfx/e9/f73i3Hbbbfn85z/Pddddx5ZbbllXPmXKFHr37s2uu+7KzjvvzJlnnsnixYvp2bMnABdffDHf/e536dOnD+PGjavb7uSTT17rGHPmzGHHHXdk//33rzsmwGOPPcbzzz9fN4dtyZIlvPzyyz6fS5LUJTkS1kpq54S9/vrrZCZjx45lzZo1bL/99kybNq3uM3v2bADOP/98zjvvPGbMmMGNN97Y4udUHXDAAcyYMYO3336b3Xffva58t91244033mDp0qX12k+dOpVBgwbVK7vwwgsZN25cvXlf48eP58UXX6Rfv37stttuvPvuu9xzzz119bVzwh5//HH23nvvuvKtttqqxT+jzOT666+v+1nMmzePI488ssXbS5LUmZiEtbIePXpw3XXXcdVVV9GjRw/69+/PXXfdBZSSkOnTpwOlUaCdd94ZgJ///OfrdYwrrrhirRGwrbbaitNPP52LLrqI1atXA3Dbbbfx/vvv88lPfrJe2549e3LSSSfVjWitWbOGO++8kxkzZvDaa6/x2muvMXHixCYvSa7LHnvswYIFC5g8eTIAS5cuZdWqVRx11FH85Cc/YeXKlQC89NJLa90AIElSV2ESVgUf/ehH2XfffRk/fjy3334748aNY/DgwQwaNIiJEycCcNlll3HiiSey33770bt37/Xa/9FHH80nPvGJtcr/9V//le7du7P77rszYMAA7rrrLu67775GH0b6la98pe4uyUmTJrHzzjuz00471dUfcsghzJo1iwULFqxXbACbb745EyZM4Pzzz2fw4MEcccQRfPDBB5x99tkMHDiQoUOHsvfee3PuueeyatWq9d6/JEmdQdQ+vqCjqKmpySlTptQrmz17NnvttVdBEakz8HdIklQNETE1M2saq3MkTJIkqQAmYZIkSQUwCZMkSSqASZgkSVIBTMIkSZIKYBImSZJUAJOwVtKtWzeGDBnC3nvvzYknnsj777+/wfsaNWpU3at9zj77bGbNmtVk26eeeopnn312vY/Rr1+/uueENSwfNmxYvbLaftV65plnOOCAA9hzzz3Zc889uemmm+rqLrvsMnr06MGf//znurKtt9663v7uv/9+IoIXX3yxyfha+vM86KCDmu+oJEntlElYK6l9bdELL7zA5ptvzg033FCvfkMfSvrTn/6UgQMHNlm/oUlYc5YuXcqbb74JUPeapVp/+tOfOPXUU7nhhht48cUXeeaZZ7jxxhv51a9+Vdemd+/eXHXVVU3uf/z48Rx88MHNPpG/pT/P1u67JEltpdMlYRdeCIce2rqfCy9cvxiGDRvG3Llzeeqppxg2bBjHHnssAwcOZPXq1Vx88cXsv//+7Lvvvtx4441A6XVG5513HnvssQeHH354vVGkQw89lNqH0z7yyCMMHTqUwYMHc9hhh/Haa69xww03cPXVVzNkyBAmTZrEwoULOf7449l///3Zf//9+e1vfwvAokWLOPLIIxk0aBBnn302zT2k96STTmLChAlAKWE65ZRT6urGjh3LqFGjGDp0KFBKuH74wx9yxRVX1LU588wzmTBhAosXL15r38uWLeOZZ55h3Lhx3HHHHRv184T6o2w/+MEP2GeffRg8eDCXXnopAK+88grDhw9nv/32Y9iwYc2OvkmS1JY6XRJWtFWrVvHwww+zzz77APCHP/yBa6+9lpdeeolx48ax3XbbMXnyZCZPnszNN9/MvHnzuO+++5gzZw6zZs3itttua3R0Z+HChZxzzjncc889TJ8+nbvuuot+/frxhS98gS9/+ctMmzaNYcOGccEFF/DlL3+ZyZMnc88993D22WcD8O1vf5uDDz6YmTNnctxxx/HGG2802Yfjjz+ee++9F4AHH3yQY445pq5u5syZ7LfffvXa19TUMHPmzLr1rbfemjPPPJNrr712rX1PnDiR4cOHs/vuu9OrVy+mTp26wT/PSg8//DATJ07k97//PdOnT+drX/saAKNHj+b6669n6tSpXHnllXzxi19s9niSJLWVTYsOoLVdc00xx/3rX//KkCFDgNLIzVlnncWzzz7LAQccQP/+/QF47LHHeP755+vmey1ZsoSXX36Zp59+mlNOOYVu3bqx0047rfXCbYDnnnuOQw45pG5fPXv2bDSOJ554ot4csnfffZdly5bx9NNP1yVWn/70p9lhhx2a7EuvXr3YYYcduOOOO9hrr73o0aPHev88vvSlLzFkyBC++tWv1isfP348F1xwAQAjR45k/PjxayV10LKfZ8N+n3HGGXWx9uzZk2XLlvHss89y4okn1rVbvnz5evdFkqRq6HRJWFFq5zA1tNVWW9UtZybXX389Rx11VL02Dz30UKvFsWbNGp577jm6d+++Ufs5+eSTGTNmDLfeemu98oEDBzJ16lRGjBhRVzZ16lQGDRpUr93222/PqaeeytixY+vKFi9ezJNPPsmMGTOICFavXk1E8KMf/Witl4y35Oe5LmvWrGH77bdvdD+SJBXNy5Ft6KijjuInP/kJK1euBOCll17ivffe45BDDmHChAmsXr2aBQsW8Jvf/GatbT/+8Y/z9NNPM2/ePIC6+VbbbLMNS5curWt35JFHcv3119et1yYghxxyCL/85S+B0qW7d955p9lYjzvuOL72ta+tlTDWJma1+120aBGXXHJJ3eW/ShdddBE33nhj3ST6u+++m9NOO43XX3+d1157jTfffJP+/fszadKkZmNpiSOOOIKf/exndXdRLl68mG233Zb+/ftz1113AaUkePr06Rt9LEmSWoNJWBs6++yzGThwIEOHDmXvvffm3HPPZdWqVRx33HEMGDCAgQMH8vnPf54DDzxwrW379OnDTTfdxOc+9zkGDx7MySefDMAxxxzDfffdVzcx/7rrrmPKlCnsu+++DBw4sO6uwm9961s8/fTTDBo0iHvvvZddd9212Vi32WYbLrnkEjbffPN65TvuuCO/+MUvOOecc9hzzz056KCDOPPMM+vNG6vVu3dvjjvuuLpLgOPHj+e4446r1+b4449v9i7Jlho+fDjHHnssNTU1DBkyhCuvvBKA22+/nXHjxjF48GAGDRrExIkTN/pYkiS1hmjuLrn2qKamJmvvFqw1e/Zs9tprr4IiUmfg75AkqRoiYmpm1jRW50iYJElSAUzCJEmSCtBpkrCOdllV7Ye/O5KkInSKJKx79+4sWrTIf0y13jKTRYsWbfQjPSRJWl+d4jlhffv2Zf78+SxcuLDoUNQBde/enb59+xYdhiSpi+kUSdhmm23W6FPUJUmS2quqXo6MiOERMSci5kbEpY3UbxERE8r1v4+IftWMR5Ikqb2oWhIWEd2AscDRwEDglIgY2KDZWcA7mfkR4GrgB9WKR5IkqT2p5kjYAcDczHw1M1cAdwAjGrQZAfy8vHw3cFg0fImgJElSJ1TNOWE7A29WrM8HPtZUm8xcFRFLgF7A25WNImI0MLq8uiwi5lQl4v/Vu2EMXUxX7n9X7jt07f7b966rK/e/K/cd2qb/H26qokNMzM/Mm4Cb2up4ETGlqVcMdAVduf9due/Qtftv37tm36Fr978r9x2K7381L0e+BexSsd63XNZom4jYFNgOWFTFmCRJktqFaiZhk4EBEdE/IjYHRgIPNGjzAHB6efkE4Mn0iauSJKkLqNrlyPIcr/OAR4FuwC2ZOTMiLgemZOYDwDjgPyJiLrCYUqLWHrTZpc92qiv3vyv3Hbp2/+1719WV+9+V+w4F9z8ceJIkSWp7neLdkZIkSR2NSZgkSVIBulwStjGvUoqIr5fL50TEUW0aeCtoQd8viohZEfF8RPw6Ij5cUbc6IqaVPw1vsOgQWtD/URGxsKKfZ1fUnR4RL5c/pzfctr1rQd+vruj3SxHxl4q6Dn3uI+KWiPhzRLzQRH1ExHXln83zETG0oq6jn/d19f0fy32eERHPRsTgirrXyuXTImJK20XdelrQ/0MjYknF7/c3K+qa/c60dy3o+8UV/X6h/D3vWa7r0Oc+InaJiN+U/z2bGREXNNKmfXzvM7PLfCjdIPAK8HfA5sB0YGCDNl8EbigvjwQmlJcHlttvAfQv76db0X1q5b5/AuhRXv4/tX0vry8rug9t0P9RwL83sm1P4NXynzuUl3couk+t2fcG7c+ndCNNZzn3hwBDgReaqP8U8DAQwMeB33eG897Cvh9U2ydKr5j7fUXda0DvovtQ5f4fCvxnI+Xr9Z1pj5919b1B22MoPZ2gU5x7YEdgaHl5G+ClRv6+bxff+642ErYxr1IaAdyRmcszcx4wt7y/jmKdfc/M32Tm++XV5yg9262zaMm5b8pRwOOZuTgz3wEeB4ZXKc5qWN++nwKMb5PI2kBmPk3p7uumjABuy5LngO0jYkc6/nlfZ98z89ly36Dzfedbcu6bsjF/X7QL69n3zvadX5CZfygvLwVmU3pDT6V28b3vaklYY69Sanhi6r1KCah9lVJLtm3P1jf+syj9L6FW94iYEhHPRcRnqxBftbW0/8eXh6bvjojahw13mXNfvgTdH3iyorijn/t1aern09HP+/pq+J1P4LGImBqlV8d1VgdGxPSIeDgiBpXLusy5j4gelJKMeyqKO825j9KUoo8Cv29Q1S6+9x3itUVqWxHxT0AN8A8VxR/OzLci4u+AJyNiRma+UkyEVfMgMD4zl0fEuZRGRD9ZcExtbSRwd2aurijrCue+S4uIT1BKwg6uKD64fN7/Bng8Il4sj650Jn+g9Pu9LCI+BdwPDCg2pDZ3DPDbzKwcNesU5z4itqaUXF6Yme8WHU9jutpI2Ma8Sqkl27ZnLYo/Ig4H/hk4NjOX15Zn5lvlP18FnqL0P4uOZJ39z8xFFX3+KbBfS7dt59Yn/pE0uCzRCc79ujT18+no571FImJfSr/vIzKz7rVxFef9z8B9dKzpFy2Sme9m5rLy8kPAZhHRmy5y7sua+8532HMfEZtRSsBuz8x7G2nSPr73bTlZrugPpZG/VyldbqmdbDmoQZsx1J+Yf2d5eRD1J+a/SseamN+Svn+U0mTUAQ3KdwC2KC/3Bl6m401SbUn/d6xYPg54rrzcE5hX/jnsUF7uWXSfWrPv5XZ7UpqQG53p3Jdj70fTk7M/Tf0Juv/dGc57C/u+K6X5rQc1KN8K2KZi+VlgeNF9qUL//7b2951SovFG+fegRd+Z9v5pru/l+u0ozRvbqjOd+/I5vA24ppk27eJ736UuR+ZGvEqp3O5OYBawChiT9S/ZtGst7PuPgK2Bu0r3IvBGZh4L7AXcGBFrKI2eXpGZswrpyAZqYf+/FBHHUjq/iyndLUlmLo6I71B6HyrA5Vl/6L5da2HfofS7fkeW/yYq6/DnPiLGU7oLrndEzAe+BWwGkJk3AA9RulNqLvA+cEa5rkOfd2hR379Jac7rj8vf+VWZWQN8CLivXLYp8MvMfKTNO7CRWtD/E4D/ExGrgL8CI8u//41+ZwrowgZrQd+h9J/NxzLzvYpNO8O5/3vgNGBGREwrl32D0n862tX33tcWSZIkFaCrzQmTJElqF0zCJEmSCmASJkmSVACTMEmSpAKYhEmSJBXAJExSpxQRvSJiWvnzp4h4q7y8LCJ+XHR8kuQjKiR1ehFxGbAsM68sOhZJquVImKQuJSIOjYj/LC9fFhE/j4hJEfF6RHwuIn4YETMi4pHyq0+IiP0i4r/KLzR+NCJ2LLYXkjoDkzBJXd1ulF7UfizwC+A3mbkPpSeof7qciF0PnJCZ+wG3AN8rKlhJnUeXem2RJDXi4cxcGREzKL2ipvYVLTMovXtvD2Bv4PHyq1y6AQsKiFNSJ2MSJqmrWw6QmWsiYmXFuzPXUPo7MoCZmXlgUQFK6py8HClJzZsD9ImIAwEiYrOIGFRwTJI6AZMwSWpGZq4ATgB+EBHTgWnAQYUGJalT8BEVkiRJBXAkTJIkqQAmYZIkSQUwCZMkSSqASZgkSVIBTMIkSZIKYBImSZJUAJMwSZKkAvx/th2uDbGETP4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test[0:y_test.shape[0]-5], color = 'red', label = 'Real MONAPrice')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted MONA Price')\n",
    "plt.title('MONA Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MONA Price')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d2dc41cbfaf67ac4a91a427b68830b69dde48fe3ce74dedd3ecbeef6226b1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
