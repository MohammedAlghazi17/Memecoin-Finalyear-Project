{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>3.039360</td>\n",
       "      <td>2.840420</td>\n",
       "      <td>2.855220</td>\n",
       "      <td>2.967630</td>\n",
       "      <td>4630550</td>\n",
       "      <td>2.967630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>2.993850</td>\n",
       "      <td>2.606440</td>\n",
       "      <td>2.959770</td>\n",
       "      <td>2.616590</td>\n",
       "      <td>3069090</td>\n",
       "      <td>2.616590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>2.714720</td>\n",
       "      <td>2.520320</td>\n",
       "      <td>2.627440</td>\n",
       "      <td>2.597220</td>\n",
       "      <td>3258960</td>\n",
       "      <td>2.597220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>3.109670</td>\n",
       "      <td>2.173080</td>\n",
       "      <td>2.598040</td>\n",
       "      <td>2.817210</td>\n",
       "      <td>9822060</td>\n",
       "      <td>2.817210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>3.254420</td>\n",
       "      <td>2.666150</td>\n",
       "      <td>2.795100</td>\n",
       "      <td>2.895720</td>\n",
       "      <td>9818930</td>\n",
       "      <td>2.895720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-23</th>\n",
       "      <td>0.885708</td>\n",
       "      <td>0.871124</td>\n",
       "      <td>0.879145</td>\n",
       "      <td>0.884427</td>\n",
       "      <td>140017</td>\n",
       "      <td>0.884427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-24</th>\n",
       "      <td>0.885972</td>\n",
       "      <td>0.868216</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.873724</td>\n",
       "      <td>136827</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-25</th>\n",
       "      <td>0.875614</td>\n",
       "      <td>0.854594</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.871669</td>\n",
       "      <td>374417</td>\n",
       "      <td>0.871669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-26</th>\n",
       "      <td>0.873849</td>\n",
       "      <td>0.848864</td>\n",
       "      <td>0.871581</td>\n",
       "      <td>0.854787</td>\n",
       "      <td>343544</td>\n",
       "      <td>0.854787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-27</th>\n",
       "      <td>0.858293</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.854772</td>\n",
       "      <td>0.857835</td>\n",
       "      <td>481151</td>\n",
       "      <td>0.857835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low      Open     Close   Volume  Adj Close\n",
       "Date                                                                  \n",
       "2017-11-09  3.039360  2.840420  2.855220  2.967630  4630550   2.967630\n",
       "2017-11-10  2.993850  2.606440  2.959770  2.616590  3069090   2.616590\n",
       "2017-11-11  2.714720  2.520320  2.627440  2.597220  3258960   2.597220\n",
       "2017-11-12  3.109670  2.173080  2.598040  2.817210  9822060   2.817210\n",
       "2017-11-13  3.254420  2.666150  2.795100  2.895720  9818930   2.895720\n",
       "...              ...       ...       ...       ...      ...        ...\n",
       "2022-04-23  0.885708  0.871124  0.879145  0.884427   140017   0.884427\n",
       "2022-04-24  0.885972  0.868216  0.884369  0.873724   136827   0.873724\n",
       "2022-04-25  0.875614  0.854594  0.873874  0.871669   374417   0.871669\n",
       "2022-04-26  0.873849  0.848864  0.871581  0.854787   343544   0.854787\n",
       "2022-04-27  0.858293  0.847107  0.854772  0.857835   481151   0.857835\n",
       "\n",
       "[1631 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doge = web.DataReader('MONA-USD', 'yahoo')\n",
    "doge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        High       Low      Open     Close   Volume  Adj Close  Polarity Score\n",
      "0   0.040466  0.038822  0.039959  0.039110  4540382   0.039110        0.095867\n",
      "1   0.021496  0.019967  0.021055  0.020416  2354228   0.020416        0.146020\n",
      "2   0.021305  0.020069  0.021282  0.020087  3187547   0.020087        0.138143\n",
      "3   0.025363  0.023064  0.024562  0.023468  8960013   0.023468        0.146417\n",
      "4   0.039302  0.037781  0.039100  0.037854  3339748   0.037854        0.071015\n",
      "5   0.022670  0.020282  0.020413  0.022599  3856593   0.022599        0.096342\n",
      "6   0.020115  0.018978  0.020089  0.018994  3477669   0.018994        0.085107\n",
      "7   0.023528  0.021745  0.023468  0.022119  5626143   0.022119        0.090832\n",
      "8   0.025356  0.024005  0.025151  0.024209  3576206   0.024209        0.113200\n",
      "9   0.017831  0.017032  0.017716  0.017041  2511868   0.017041        0.111060\n",
      "10  0.020210  0.018104  0.018191  0.020164  8103112   0.020164        0.119920\n",
      "11  0.024229  0.022444  0.024200  0.022548  7630065   0.022548        0.367391\n",
      "12  0.017329  0.016840  0.017040  0.017236  2672658   0.017236        0.075841\n",
      "13  0.020323  0.019238  0.020165  0.019463  3093349   0.019463        0.167889\n",
      "14  0.024639  0.022546  0.022549  0.024553  4922000   0.024553        0.150535\n",
      "15  0.017277  0.017021  0.017235  0.017197  2181533   0.017197        0.100922\n",
      "16  0.019857  0.019464  0.019464  0.019609  2572785   0.019609        0.115242\n",
      "17  0.024668  0.023574  0.024555  0.024255  4960041   0.024255        0.010105\n",
      "18  0.017694  0.017169  0.017197  0.017450  2758192   0.017450        0.076036\n",
      "19  0.019650  0.019349  0.019612  0.019387  2396187   0.019387        0.131267\n",
      "20  0.024255  0.022148  0.024255  0.022179  5654043   0.022179        0.232539\n",
      "21  0.017590  0.016953  0.017450  0.016968  1406402   0.016968        0.133072\n",
      "22  0.019571  0.019280  0.019389  0.019403  2455887   0.019403        0.129466\n",
      "23  0.022231  0.021466  0.022183  0.021707  4788922   0.021707        0.245144\n",
      "24  0.016976  0.016487  0.016966  0.016792  1489717   0.016792        0.089275\n",
      "25  0.019441  0.018025  0.019405  0.018616  5012752   0.018616        0.141833\n",
      "26  0.022165  0.020626  0.021706  0.020718  4329773   0.020718        0.000168\n",
      "27  0.017582  0.016755  0.016791  0.017352  2899828   0.017352        0.223525\n",
      "28  0.018966  0.018497  0.018616  0.018816  5220647   0.018816        0.141011\n",
      "29  0.020726  0.019703  0.020718  0.020130  3606275   0.020130        0.219473\n",
      "30  0.017400  0.016915  0.017358  0.016969  2326913   0.016969        0.110555\n",
      "31  0.019690  0.018713  0.018814  0.019443  6197703   0.019443        0.127655\n",
      "32  0.021330  0.019650  0.020128  0.019669  6410944   0.019669        0.135519\n",
      "33  0.017055  0.016787  0.016965  0.016826  2465017   0.016826        0.115944\n",
      "34  0.019837  0.018894  0.019448  0.018932  4985870   0.018932        0.131129\n",
      "35  0.020590  0.019308  0.019666  0.020017  4479372   0.020017        0.112503\n",
      "36  0.017141  0.016786  0.016826  0.017052  1816183   0.017052        0.000000\n",
      "37  0.019078  0.018670  0.018934  0.018782  4510713   0.018782        0.112926\n",
      "38  0.021261  0.019645  0.020018  0.019849  6560793   0.019849        0.153502\n",
      "39  0.018121  0.016949  0.017052  0.018121  2965883   0.018121        0.140484\n",
      "40  0.018830  0.018224  0.018781  0.018250  2805040   0.018250        0.121865\n",
      "41  0.019866  0.018117  0.019845  0.019317  6809540   0.019317        0.109284\n",
      "42  0.020732  0.018032  0.018119  0.020348  9816389   0.020348        0.117736\n",
      "43  0.018346  0.017593  0.018255  0.017611  3187244   0.017611        0.101390\n",
      "44  0.019998  0.019317  0.019317  0.019792  4146367   0.019792        0.107181\n",
      "45  0.020474  0.018772  0.020347  0.018785  4717640   0.018785        0.161422\n",
      "46  0.017812  0.016565  0.017608  0.017794  5457613   0.017794        0.123299\n",
      "47  0.020020  0.019501  0.019788  0.019572  2705655   0.019572        0.141459\n",
      "48  0.018802  0.017917  0.018784  0.017958  4135019   0.017958        0.227658\n",
      "49  0.017899  0.015870  0.017794  0.015871  5393058   0.015871        0.164302\n",
      "50  0.019717  0.018994  0.019571  0.019032  2986155   0.019032        0.199485\n",
      "51  0.018451  0.017323  0.017959  0.018451  4786987   0.018451        0.169030\n",
      "52  0.020250  0.018959  0.019031  0.020227  4104610   0.020227        0.131502\n",
      "53  0.022508  0.018430  0.018451  0.022424  7971828   0.022424        0.153586\n",
      "54  0.023269  0.022024  0.022421  0.022790  3532996   0.022790        0.114973\n",
      "55  0.022805  0.021691  0.022789  0.022610  5609570   0.022610        0.107061\n",
      "56  0.022841  0.021453  0.022609  0.021560  5378382   0.021560        0.083907\n"
     ]
    }
   ],
   "source": [
    "#lstm_data = np.genfromtxt('./sample_data/lstm.csv', delimiter=',', skip_header=True)\n",
    "lstm_data = read_csv('lstmsamo.csv')\n",
    "lstm_data = lstm_data.drop(['Date'], axis=1)\n",
    "print(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X = lstm_data.drop(['Close'], axis=1)\n",
    "lstm_data_y = lstm_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 5 # how many days to look back\n",
    "batch_size = 3 # size of batches used when training\n",
    "n_feat = 6 # number of features \n",
    "n_target = 2\n",
    "n_validation = 6\n",
    "n_test = 8\n",
    "n_train = lstm_data_X.shape[0] - n_validation - n_test - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_data_X_train = lstm_data_X.iloc[:30,:]\n",
    "#lstm_data_X_val = lstm_data_X.iloc[30:40,:]\n",
    "#lstm_data_X_test = lstm_data_X.iloc[40:52,:]\n",
    "\n",
    "#lstm_data_y_train = lstm_data_y.iloc[:30]\n",
    "#lstm_data_y_val = lstm_data_y.iloc[30:40]\n",
    "#lstm_data_y_test = lstm_data_y.iloc[40:52]\n",
    "# Convert to numpy arrays\n",
    "#X_train = lstm_data_X_train.to_numpy()\n",
    "#X_val = lstm_data_X_val.to_numpy()\n",
    "#X_test = lstm_data_X_test.to_numpy()\n",
    "#y_train = lstm_data_y_train.to_numpy()\n",
    "#y_val = lstm_data_y_val.to_numpy()\n",
    "#y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X_train = lstm_data_X.iloc[:n_train,:]\n",
    "lstm_data_X_val = lstm_data_X.iloc[n_train:n_train + n_validation,:]\n",
    "lstm_data_X_test = lstm_data_X.iloc[n_train + n_validation:n_train + n_validation + n_test,:]\n",
    "\n",
    "lstm_data_y_train = lstm_data_y.iloc[:n_train]\n",
    "lstm_data_y_val = lstm_data_y.iloc[n_train:n_train + n_validation]\n",
    "lstm_data_y_test = lstm_data_y.iloc[n_train + n_validation:n_train + n_validation + n_test]\n",
    "# Convert to numpy arrays\n",
    "X_train = lstm_data_X_train.to_numpy()\n",
    "X_val = lstm_data_X_val.to_numpy()\n",
    "X_test = lstm_data_X_test.to_numpy()\n",
    "y_train = lstm_data_y_train.to_numpy()\n",
    "y_val = lstm_data_y_val.to_numpy()\n",
    "y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.88020002e-02, 1.79169998e-02, 1.87839996e-02, 4.13501900e+06,\n",
       "        1.79580003e-02, 2.27658000e-01],\n",
       "       [1.78989992e-02, 1.58699993e-02, 1.77940000e-02, 5.39305800e+06,\n",
       "        1.58709995e-02, 1.64302360e-01],\n",
       "       [1.97170004e-02, 1.89939998e-02, 1.95710007e-02, 2.98615500e+06,\n",
       "        1.90319996e-02, 1.99485454e-01],\n",
       "       [1.84509996e-02, 1.73230004e-02, 1.79590005e-02, 4.78698700e+06,\n",
       "        1.84509996e-02, 1.69029840e-01],\n",
       "       [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "        2.02270001e-02, 1.31502325e-01],\n",
       "       [2.25079991e-02, 1.84300002e-02, 1.84509996e-02, 7.97182800e+06,\n",
       "        2.24239994e-02, 1.53586280e-01],\n",
       "       [2.32689995e-02, 2.20240001e-02, 2.24210005e-02, 3.53299600e+06,\n",
       "        2.27899998e-02, 1.14973180e-01],\n",
       "       [2.28049997e-02, 2.16910001e-02, 2.27889996e-02, 5.60957000e+06,\n",
       "        2.26099994e-02, 1.07060620e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.017958, 0.015871, 0.019032, 0.018451, 0.020227, 0.022424,\n",
       "       0.02279 , 0.02261 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = TimeseriesGenerator(X_train, y_train, length=look_back, batch_size=batch_size)\n",
    "val_data_gen = TimeseriesGenerator(X_val, y_val, length=look_back, batch_size=batch_size)\n",
    "test_data_gen = TimeseriesGenerator(X_test, y_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(1, 5, 6) (1,)\n"
     ]
    }
   ],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(train_data_gen)):\n",
    "    x, y = train_data_gen[i]\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 5, 32)             4992      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 32)             0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,345\n",
      "Trainable params: 13,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, input_shape=(look_back, n_feat), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(LSTM(32))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_22012/192094070.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model_lstm.fit_generator(train_data_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 143ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 4.0313e-04 - val_mse: 4.0313e-04\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 6.9767e-04 - val_mse: 6.9767e-04\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.8671e-04 - val_mse: 1.8671e-04\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 2.1917e-04 - val_mse: 2.1917e-04\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 1.3789e-04 - val_mse: 1.3789e-04\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.0892e-04 - val_mse: 1.0892e-04\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 4.3039e-06 - val_mse: 4.3039e-06\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 6.1648e-04 - val_mse: 6.1648e-04\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 2.0302e-04 - val_mse: 2.0302e-04\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 3.7580e-04 - val_mse: 3.7580e-04\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 5.3578e-06 - val_mse: 5.3578e-06\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 8.3982e-05 - val_mse: 8.3982e-05\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.5445e-04 - val_mse: 2.5445e-04\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 2.2969e-05 - val_mse: 2.2969e-05\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.1402e-04 - val_mse: 1.1402e-04\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 8.9630e-05 - val_mse: 8.9630e-05\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.1674e-04 - val_mse: 1.1674e-04\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0011 - val_mse: 0.0011\n"
     ]
    }
   ],
   "source": [
    "hist = model_lstm.fit_generator(train_data_gen,\n",
    "                                        steps_per_epoch=10,\n",
    "                                        epochs=20,\n",
    "                                        verbose=1,\n",
    "                                        validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_lstm.predict(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1.88020002e-02, 1.79169998e-02, 1.87839996e-02, 4.13501900e+06,\n",
       "          1.79580003e-02, 2.27658000e-01],\n",
       "         [1.78989992e-02, 1.58699993e-02, 1.77940000e-02, 5.39305800e+06,\n",
       "          1.58709995e-02, 1.64302360e-01],\n",
       "         [1.97170004e-02, 1.89939998e-02, 1.95710007e-02, 2.98615500e+06,\n",
       "          1.90319996e-02, 1.99485454e-01],\n",
       "         [1.84509996e-02, 1.73230004e-02, 1.79590005e-02, 4.78698700e+06,\n",
       "          1.84509996e-02, 1.69029840e-01],\n",
       "         [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "          2.02270001e-02, 1.31502325e-01]],\n",
       " \n",
       "        [[1.78989992e-02, 1.58699993e-02, 1.77940000e-02, 5.39305800e+06,\n",
       "          1.58709995e-02, 1.64302360e-01],\n",
       "         [1.97170004e-02, 1.89939998e-02, 1.95710007e-02, 2.98615500e+06,\n",
       "          1.90319996e-02, 1.99485454e-01],\n",
       "         [1.84509996e-02, 1.73230004e-02, 1.79590005e-02, 4.78698700e+06,\n",
       "          1.84509996e-02, 1.69029840e-01],\n",
       "         [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "          2.02270001e-02, 1.31502325e-01],\n",
       "         [2.25079991e-02, 1.84300002e-02, 1.84509996e-02, 7.97182800e+06,\n",
       "          2.24239994e-02, 1.53586280e-01]],\n",
       " \n",
       "        [[1.97170004e-02, 1.89939998e-02, 1.95710007e-02, 2.98615500e+06,\n",
       "          1.90319996e-02, 1.99485454e-01],\n",
       "         [1.84509996e-02, 1.73230004e-02, 1.79590005e-02, 4.78698700e+06,\n",
       "          1.84509996e-02, 1.69029840e-01],\n",
       "         [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "          2.02270001e-02, 1.31502325e-01],\n",
       "         [2.25079991e-02, 1.84300002e-02, 1.84509996e-02, 7.97182800e+06,\n",
       "          2.24239994e-02, 1.53586280e-01],\n",
       "         [2.32689995e-02, 2.20240001e-02, 2.24210005e-02, 3.53299600e+06,\n",
       "          2.27899998e-02, 1.14973180e-01]]]),\n",
       " array([0.022424, 0.02279 , 0.02261 ]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01335494],\n",
       "       [-0.01335494],\n",
       "       [-0.01335494]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test[0:y_test.shape[0]-5], color = 'red', label = 'Real MONAPrice')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted MONA Price')\n",
    "plt.title('MONA Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MONA Price')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d2dc41cbfaf67ac4a91a427b68830b69dde48fe3ce74dedd3ecbeef6226b1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
