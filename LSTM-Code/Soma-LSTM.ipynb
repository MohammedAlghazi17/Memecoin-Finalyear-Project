{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>3.039360</td>\n",
       "      <td>2.840420</td>\n",
       "      <td>2.855220</td>\n",
       "      <td>2.967630</td>\n",
       "      <td>4630550</td>\n",
       "      <td>2.967630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>2.993850</td>\n",
       "      <td>2.606440</td>\n",
       "      <td>2.959770</td>\n",
       "      <td>2.616590</td>\n",
       "      <td>3069090</td>\n",
       "      <td>2.616590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>2.714720</td>\n",
       "      <td>2.520320</td>\n",
       "      <td>2.627440</td>\n",
       "      <td>2.597220</td>\n",
       "      <td>3258960</td>\n",
       "      <td>2.597220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>3.109670</td>\n",
       "      <td>2.173080</td>\n",
       "      <td>2.598040</td>\n",
       "      <td>2.817210</td>\n",
       "      <td>9822060</td>\n",
       "      <td>2.817210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>3.254420</td>\n",
       "      <td>2.666150</td>\n",
       "      <td>2.795100</td>\n",
       "      <td>2.895720</td>\n",
       "      <td>9818930</td>\n",
       "      <td>2.895720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-24</th>\n",
       "      <td>0.885972</td>\n",
       "      <td>0.868216</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.873724</td>\n",
       "      <td>136827</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-25</th>\n",
       "      <td>0.875614</td>\n",
       "      <td>0.854594</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.871669</td>\n",
       "      <td>374417</td>\n",
       "      <td>0.871669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-26</th>\n",
       "      <td>0.873849</td>\n",
       "      <td>0.848864</td>\n",
       "      <td>0.871581</td>\n",
       "      <td>0.854787</td>\n",
       "      <td>343544</td>\n",
       "      <td>0.854787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-27</th>\n",
       "      <td>0.874509</td>\n",
       "      <td>0.846216</td>\n",
       "      <td>0.854779</td>\n",
       "      <td>0.853320</td>\n",
       "      <td>290011</td>\n",
       "      <td>0.853320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-28</th>\n",
       "      <td>0.861331</td>\n",
       "      <td>0.836389</td>\n",
       "      <td>0.851945</td>\n",
       "      <td>0.845403</td>\n",
       "      <td>195645</td>\n",
       "      <td>0.845403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1632 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low      Open     Close   Volume  Adj Close\n",
       "Date                                                                  \n",
       "2017-11-09  3.039360  2.840420  2.855220  2.967630  4630550   2.967630\n",
       "2017-11-10  2.993850  2.606440  2.959770  2.616590  3069090   2.616590\n",
       "2017-11-11  2.714720  2.520320  2.627440  2.597220  3258960   2.597220\n",
       "2017-11-12  3.109670  2.173080  2.598040  2.817210  9822060   2.817210\n",
       "2017-11-13  3.254420  2.666150  2.795100  2.895720  9818930   2.895720\n",
       "...              ...       ...       ...       ...      ...        ...\n",
       "2022-04-24  0.885972  0.868216  0.884369  0.873724   136827   0.873724\n",
       "2022-04-25  0.875614  0.854594  0.873874  0.871669   374417   0.871669\n",
       "2022-04-26  0.873849  0.848864  0.871581  0.854787   343544   0.854787\n",
       "2022-04-27  0.874509  0.846216  0.854779  0.853320   290011   0.853320\n",
       "2022-04-28  0.861331  0.836389  0.851945  0.845403   195645   0.845403\n",
       "\n",
       "[1632 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doge = web.DataReader('MONA-USD', 'yahoo')\n",
    "doge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        High       Low      Open     Close   Volume  Adj Close  Polarity Score\n",
      "0   0.040466  0.038822  0.039959  0.039110  4540382   0.039110        0.095867\n",
      "1   0.021496  0.019967  0.021055  0.020416  2354228   0.020416        0.146020\n",
      "2   0.021305  0.020069  0.021282  0.020087  3187547   0.020087        0.138143\n",
      "3   0.025363  0.023064  0.024562  0.023468  8960013   0.023468        0.146417\n",
      "4   0.039302  0.037781  0.039100  0.037854  3339748   0.037854        0.071015\n",
      "5   0.022670  0.020282  0.020413  0.022599  3856593   0.022599        0.096342\n",
      "6   0.020115  0.018978  0.020089  0.018994  3477669   0.018994        0.085107\n",
      "7   0.023528  0.021745  0.023468  0.022119  5626143   0.022119        0.090832\n",
      "8   0.025356  0.024005  0.025151  0.024209  3576206   0.024209        0.113200\n",
      "9   0.017831  0.017032  0.017716  0.017041  2511868   0.017041        0.111060\n",
      "10  0.020210  0.018104  0.018191  0.020164  8103112   0.020164        0.119920\n",
      "11  0.024229  0.022444  0.024200  0.022548  7630065   0.022548        0.367391\n",
      "12  0.017329  0.016840  0.017040  0.017236  2672658   0.017236        0.075841\n",
      "13  0.020323  0.019238  0.020165  0.019463  3093349   0.019463        0.167889\n",
      "14  0.024639  0.022546  0.022549  0.024553  4922000   0.024553        0.150535\n",
      "15  0.017277  0.017021  0.017235  0.017197  2181533   0.017197        0.100922\n",
      "16  0.019857  0.019464  0.019464  0.019609  2572785   0.019609        0.115242\n",
      "17  0.024668  0.023574  0.024555  0.024255  4960041   0.024255        0.010105\n",
      "18  0.017694  0.017169  0.017197  0.017450  2758192   0.017450        0.076036\n",
      "19  0.019650  0.019349  0.019612  0.019387  2396187   0.019387        0.131267\n",
      "20  0.024255  0.022148  0.024255  0.022179  5654043   0.022179        0.232539\n",
      "21  0.017590  0.016953  0.017450  0.016968  1406402   0.016968        0.133072\n",
      "22  0.019571  0.019280  0.019389  0.019403  2455887   0.019403        0.129466\n",
      "23  0.022231  0.021466  0.022183  0.021707  4788922   0.021707        0.245144\n",
      "24  0.016976  0.016487  0.016966  0.016792  1489717   0.016792        0.089275\n",
      "25  0.019441  0.018025  0.019405  0.018616  5012752   0.018616        0.141833\n",
      "26  0.022165  0.020626  0.021706  0.020718  4329773   0.020718        0.000168\n",
      "27  0.017582  0.016755  0.016791  0.017352  2899828   0.017352        0.223525\n",
      "28  0.018966  0.018497  0.018616  0.018816  5220647   0.018816        0.141011\n",
      "29  0.020726  0.019703  0.020718  0.020130  3606275   0.020130        0.219473\n",
      "30  0.017400  0.016915  0.017358  0.016969  2326913   0.016969        0.110555\n",
      "31  0.019690  0.018713  0.018814  0.019443  6197703   0.019443        0.127655\n",
      "32  0.021330  0.019650  0.020128  0.019669  6410944   0.019669        0.135519\n",
      "33  0.017055  0.016787  0.016965  0.016826  2465017   0.016826        0.115944\n",
      "34  0.019837  0.018894  0.019448  0.018932  4985870   0.018932        0.131129\n",
      "35  0.020590  0.019308  0.019666  0.020017  4479372   0.020017        0.112503\n",
      "36  0.017141  0.016786  0.016826  0.017052  1816183   0.017052        0.000000\n",
      "37  0.019078  0.018670  0.018934  0.018782  4510713   0.018782        0.112926\n",
      "38  0.021261  0.019645  0.020018  0.019849  6560793   0.019849        0.153502\n",
      "39  0.018121  0.016949  0.017052  0.018121  2965883   0.018121        0.140484\n",
      "40  0.018830  0.018224  0.018781  0.018250  2805040   0.018250        0.121865\n",
      "41  0.019866  0.018117  0.019845  0.019317  6809540   0.019317        0.109284\n",
      "42  0.020732  0.018032  0.018119  0.020348  9816389   0.020348        0.117736\n",
      "43  0.018346  0.017593  0.018255  0.017611  3187244   0.017611        0.101390\n",
      "44  0.019998  0.019317  0.019317  0.019792  4146367   0.019792        0.107181\n",
      "45  0.020474  0.018772  0.020347  0.018785  4717640   0.018785        0.161422\n",
      "46  0.017812  0.016565  0.017608  0.017794  5457613   0.017794        0.123299\n",
      "47  0.020020  0.019501  0.019788  0.019572  2705655   0.019572        0.141459\n",
      "48  0.018802  0.017917  0.018784  0.017958  4135019   0.017958        0.227658\n",
      "49  0.017899  0.015870  0.017794  0.015871  5393058   0.015871        0.164302\n",
      "50  0.019717  0.018994  0.019571  0.019032  2986155   0.019032        0.199485\n",
      "51  0.018451  0.017323  0.017959  0.018451  4786987   0.018451        0.169030\n",
      "52  0.016091  0.015683  0.015872  0.015803  4580198   0.015803        0.148283\n",
      "53  0.020250  0.018959  0.019031  0.020227  4104610   0.020227        0.131502\n",
      "54  0.022508  0.018430  0.018451  0.022424  7971828   0.022424        0.153586\n",
      "55  0.015957  0.015737  0.015813  0.015820  4205155   0.015820        0.128671\n",
      "56  0.023269  0.022024  0.022421  0.022790  3532996   0.022790        0.114973\n",
      "57  0.022805  0.021691  0.022789  0.022610  5609570   0.022610        0.107061\n",
      "58  0.022841  0.021453  0.022609  0.021560  5378382   0.021560        0.083907\n"
     ]
    }
   ],
   "source": [
    "#lstm_data = np.genfromtxt('./sample_data/lstm.csv', delimiter=',', skip_header=True)\n",
    "lstm_data = read_csv('lstmsoma.csv')\n",
    "lstm_data = lstm_data.drop(['Date'], axis=1)\n",
    "print(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X = lstm_data.drop(['Close'], axis=1)\n",
    "lstm_data_y = lstm_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 5 # how many days to look back\n",
    "batch_size = 3 # size of batches used when training\n",
    "n_feat = 6 # number of features \n",
    "n_target = 2\n",
    "n_validation = 6\n",
    "n_test = 8\n",
    "n_train = lstm_data_X.shape[0] - n_validation - n_test - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_data_X_train = lstm_data_X.iloc[:30,:]\n",
    "#lstm_data_X_val = lstm_data_X.iloc[30:40,:]\n",
    "#lstm_data_X_test = lstm_data_X.iloc[40:52,:]\n",
    "\n",
    "#lstm_data_y_train = lstm_data_y.iloc[:30]\n",
    "#lstm_data_y_val = lstm_data_y.iloc[30:40]\n",
    "#lstm_data_y_test = lstm_data_y.iloc[40:52]\n",
    "# Convert to numpy arrays\n",
    "#X_train = lstm_data_X_train.to_numpy()\n",
    "#X_val = lstm_data_X_val.to_numpy()\n",
    "#X_test = lstm_data_X_test.to_numpy()\n",
    "#y_train = lstm_data_y_train.to_numpy()\n",
    "#y_val = lstm_data_y_val.to_numpy()\n",
    "#y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_X_train = lstm_data_X.iloc[:n_train,:]\n",
    "lstm_data_X_val = lstm_data_X.iloc[n_train:n_train + n_validation,:]\n",
    "lstm_data_X_test = lstm_data_X.iloc[n_train + n_validation:n_train + n_validation + n_test,:]\n",
    "\n",
    "lstm_data_y_train = lstm_data_y.iloc[:n_train]\n",
    "lstm_data_y_val = lstm_data_y.iloc[n_train:n_train + n_validation]\n",
    "lstm_data_y_test = lstm_data_y.iloc[n_train + n_validation:n_train + n_validation + n_test]\n",
    "# Convert to numpy arrays\n",
    "X_train = lstm_data_X_train.to_numpy()\n",
    "X_val = lstm_data_X_val.to_numpy()\n",
    "X_test = lstm_data_X_test.to_numpy()\n",
    "y_train = lstm_data_y_train.to_numpy()\n",
    "y_val = lstm_data_y_val.to_numpy()\n",
    "y_test = lstm_data_y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.97170004e-02, 1.89939998e-02, 1.95710007e-02, 2.98615500e+06,\n",
       "        1.90319996e-02, 1.99485454e-01],\n",
       "       [1.84509996e-02, 1.73230004e-02, 1.79590005e-02, 4.78698700e+06,\n",
       "        1.84509996e-02, 1.69029840e-01],\n",
       "       [1.60910003e-02, 1.56830009e-02, 1.58719998e-02, 4.58019800e+06,\n",
       "        1.58030000e-02, 1.48283467e-01],\n",
       "       [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "        2.02270001e-02, 1.31502325e-01],\n",
       "       [2.25079991e-02, 1.84300002e-02, 1.84509996e-02, 7.97182800e+06,\n",
       "        2.24239994e-02, 1.53586280e-01],\n",
       "       [1.59573741e-02, 1.57366004e-02, 1.58132315e-02, 4.20515500e+06,\n",
       "        1.58201400e-02, 1.28670540e-01],\n",
       "       [2.32689995e-02, 2.20240001e-02, 2.24210005e-02, 3.53299600e+06,\n",
       "        2.27899998e-02, 1.14973180e-01],\n",
       "       [2.28049997e-02, 2.16910001e-02, 2.27889996e-02, 5.60957000e+06,\n",
       "        2.26099994e-02, 1.07060620e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.019032  , 0.018451  , 0.015803  , 0.020227  , 0.022424  ,\n",
       "       0.01582014, 0.02279   , 0.02261   ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = TimeseriesGenerator(X_train, y_train, length=look_back, batch_size=batch_size)\n",
    "val_data_gen = TimeseriesGenerator(X_val, y_val, length=look_back, batch_size=batch_size)\n",
    "test_data_gen = TimeseriesGenerator(X_test, y_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n",
      "(3, 5, 6) (3,)\n"
     ]
    }
   ],
   "source": [
    "# check generator dimensions\n",
    "for i in range(len(train_data_gen)):\n",
    "    x, y = train_data_gen[i]\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 5, 32)             4992      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 32)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,345\n",
      "Trainable params: 13,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, input_shape=(look_back, n_feat), return_sequences=True))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(LSTM(32))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_30008/192094070.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model_lstm.fit_generator(train_data_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 97ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 6.9106e-04 - val_mse: 6.9106e-04\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 1.5287e-04 - val_mse: 1.5287e-04\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 9.9615e-04 - val_mse: 9.9615e-04\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 5.1504e-05 - val_mse: 5.1504e-05\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 3.4630e-05 - val_mse: 3.4630e-05\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.3351e-05 - val_mse: 1.3351e-05\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 9.3489e-05 - val_mse: 9.3489e-05\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 7.8810e-05 - val_mse: 7.8810e-05\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.2101e-04 - val_mse: 1.2101e-04\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 5.8945e-04 - val_mse: 5.8945e-04\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 3.1642e-04 - val_mse: 3.1642e-04\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 3.2694e-04 - val_mse: 3.2694e-04\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 9.4519e-05 - val_mse: 9.4519e-05\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 9.5719e-04 - val_mse: 9.5719e-04\n"
     ]
    }
   ],
   "source": [
    "hist = model_lstm.fit_generator(train_data_gen,\n",
    "                                        steps_per_epoch=10,\n",
    "                                        epochs=20,\n",
    "                                        verbose=1,\n",
    "                                        validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_lstm.predict(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1.97170004e-02, 1.89939998e-02, 1.95710007e-02, 2.98615500e+06,\n",
       "          1.90319996e-02, 1.99485454e-01],\n",
       "         [1.84509996e-02, 1.73230004e-02, 1.79590005e-02, 4.78698700e+06,\n",
       "          1.84509996e-02, 1.69029840e-01],\n",
       "         [1.60910003e-02, 1.56830009e-02, 1.58719998e-02, 4.58019800e+06,\n",
       "          1.58030000e-02, 1.48283467e-01],\n",
       "         [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "          2.02270001e-02, 1.31502325e-01],\n",
       "         [2.25079991e-02, 1.84300002e-02, 1.84509996e-02, 7.97182800e+06,\n",
       "          2.24239994e-02, 1.53586280e-01]],\n",
       " \n",
       "        [[1.84509996e-02, 1.73230004e-02, 1.79590005e-02, 4.78698700e+06,\n",
       "          1.84509996e-02, 1.69029840e-01],\n",
       "         [1.60910003e-02, 1.56830009e-02, 1.58719998e-02, 4.58019800e+06,\n",
       "          1.58030000e-02, 1.48283467e-01],\n",
       "         [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "          2.02270001e-02, 1.31502325e-01],\n",
       "         [2.25079991e-02, 1.84300002e-02, 1.84509996e-02, 7.97182800e+06,\n",
       "          2.24239994e-02, 1.53586280e-01],\n",
       "         [1.59573741e-02, 1.57366004e-02, 1.58132315e-02, 4.20515500e+06,\n",
       "          1.58201400e-02, 1.28670540e-01]],\n",
       " \n",
       "        [[1.60910003e-02, 1.56830009e-02, 1.58719998e-02, 4.58019800e+06,\n",
       "          1.58030000e-02, 1.48283467e-01],\n",
       "         [2.02500001e-02, 1.89590007e-02, 1.90309994e-02, 4.10461000e+06,\n",
       "          2.02270001e-02, 1.31502325e-01],\n",
       "         [2.25079991e-02, 1.84300002e-02, 1.84509996e-02, 7.97182800e+06,\n",
       "          2.24239994e-02, 1.53586280e-01],\n",
       "         [1.59573741e-02, 1.57366004e-02, 1.58132315e-02, 4.20515500e+06,\n",
       "          1.58201400e-02, 1.28670540e-01],\n",
       "         [2.32689995e-02, 2.20240001e-02, 2.24210005e-02, 3.53299600e+06,\n",
       "          2.27899998e-02, 1.14973180e-01]]]),\n",
       " array([0.01582014, 0.02279   , 0.02261   ]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04680951],\n",
       "       [0.04680951],\n",
       "       [0.04680951]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test[0:y_test.shape[0]-5], color = 'red', label = 'Real MONAPrice')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted MONA Price')\n",
    "plt.title('MONA Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MONA Price')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d2dc41cbfaf67ac4a91a427b68830b69dde48fe3ce74dedd3ecbeef6226b1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
